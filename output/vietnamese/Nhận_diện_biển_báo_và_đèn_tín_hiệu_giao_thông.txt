1.1 Đặt vấn đề Bài toán nhận diện vật thể ngày càng phổ biến trong đời sống của chúng ta. Hơn một thập kỷ qua, có rất nhiều công trình nghiên cứu về bài toán xác định vật thể.
Các nghiên cứu đi từ đơn giản là bức ảnh chỉ có một vật, rồi một vật với số lượng nhiều trong một ảnh, và sau đó là nhiều vật trong cùng một bức ảnh. Bên cạnh việc nhận diện, phát hiện được vị trí của vật thể, một công việc khó khăn hơn chính là làm sao để xác định được chi tiết của từng đối tượng đến từng điểm ảnh trong bức ảnh. Cùng với sự chính xác trong việc nhận diện chính là tốc độ cần đủ để nhận diện vật thể trong thời gian thực đáp ứng nhu cầu thực tiễn cần thiết cho con người.
Computer vision có khá nhiều các nhiệm vụ khác nhau và đôi khi ta gặp khó khăn trong việc phân biệt các nhiệm vụ này. Chẳng hạn như phân loại hình ảnh (image classification) là gì? Định vị vật thể (object localization) là gì? Sự khác biệt giữa định vị vật thể (object localization) và phát hiện đối tượng (object detection) là gì? Đây là những khái niệm có thể gây nhầm lẫn, đặc biệt là khi cả ba nhiệm vụ đều liên quan đến nhau. Hiều một cách đơn giản:
Phân loại hình ảnh (image classification): liên quan đến việc gán nhãn cho hình ảnh.
Định vị vật thể (object localization): liên quan đến việc vẽ một hộp giới hạn (bounding box) xung quanh một hoặc nhiều đối tượng trong hình ảnh nhằm khoanh vùng đối tượng.
Phát hiện đối tượng (object detection): Là nhiệm vụ khó khăn hơn và là sự kết hợp của cả hai nhiệm vụ trên: Vẽ một bounding box xung quanh từng đối tượng quan tâm trong ảnh và gán cho chúng một nhãn. Kết hợp cùng nhau, tất cả các vấn đề này được gọi là object recognition hoặc object detection.
Phân loại hình ảnh liên quan đến việc dự đoán lớp của một đối tượng trong một hình ảnh. Định vị vật thể đề cập đến việc xác định vị trí của một hoặc nhiều đối tượng trong một hình ảnh và vẽ bounding box xung quanh chúng. Phát hiện đối tượng kết hợp hai nhiệm vụ trên và thực hiện cho một hoặc nhiều đối tượng trong hình ảnh. Chúng ta có thể phân biệt giữa ba nhiệm vụ thị giác máy tính cơ bản trên thông qua input và output của chúng như sau:
Phân loại hình ảnh: Dự đoán nhãn của một đối tượng trong một hình ảnh –Input: Một hình ảnh với một đối tượng, chẳng hạn như một bức ảnh.
1–Output: Nhãn lớp (ví dụ: một hoặc nhiều số nguyên được ánh xạ tới nhãn lớp).
Định vị đối tượng: Xác định vị trí hiện diện của các đối tượng trong ảnh và cho biết vị trí của chúng bằng bounding box.
–Input: Một hình ảnh có một hoặc nhiều đối tượng, chẳng hạn như một bức ảnh.
–Output: Một hoặc nhiều bounding box được xác định bởi tọa độ tâm, chiều rộng và chiều cao.
Phát hiện đối tượng: Xác định vị trí hiện diện của các đối tượng trong bounding box và nhãn của các đối tượng nằm trong một hình ảnh.
–Input: Một hình ảnh có một hoặc nhiều đối tượng, chẳng hạn như một bức ảnh.
–Một hoặc nhiều bounding box và nhãn cho mỗi bounding box.
Bài toán phát hiện đối tượng đóng vai trò quan trọng trong các hệ thống phát hiện các khối u trong cơ thể người hay phát hiện làn đường , các vật thể cản trở giao thông, biển báo, đèn tín hiệu giao thông ... Bài toán phát hiện đối tượng giúp ích rất nhiều trong cuộc sống.
NogiCargo là một phần mềm hỗ trợ cho việc điều khiển xe tự dộng do đội ngũ bộ phận IT công ty NSMV xây dựng và phát triển. Phần mềm cung cấp các tính năng để tự hành cho ô tô mà không cần đến sự tham gia của con người. Những tính năng chính mà phần mềm cung cấp có thể kể đến như: sử dụng bản đồ và GPS để xác định cung đường đi cho thuận tiện, nhận dạng các biển báo và đèn tín hiệu giao thông, phát hiện và theo dõi các phương tiện, vật cản xuất hiện trên đường,nhận diện vạch kẻ, làn đường, ... Và trong quá trình thực tập tại công ty, em đã vinh dự được tham gia vào quá trình nghiên cứu và phát triển phần mềm, cụ thể là xây dựng hệ thống nhận diện đèn tín hiệu và biển báo giao thông. Sau quá trình tham gia dự án cũng như được sự hỗ trợ, giúp đỡ của các anh chị trong công ty, hệ thống của em cũng đã có những kết quả khả quan. Vì vậy trong đồ án lần này em xin phép được trình bày những công việc và kết quả em đã tìm hiểu và xây dựng được trong thời gian tham gia xây dựng phần mềm NogiCargo.
Giới thiệu qua về tầm quan trọng của hệ thống, trong thời đại công nghệ phát triển, tai nạn giao thông vẫn là một vấn đề được quan tâm thường ngày. Để giúp cho việc tham gia giao thông an toàn hơn, giảm thiểu các vụ tại nạn giao thông đáng tiếc xảy ra cần một hệ thống hỗ trợ phát hiện vật cản cũng như phát hiện biển báo, đèn tín hiệu. Hệ thống sẽ giúp cho việc xác định nguy hiểm khi gặp vật cản 2cũng như giúp cho người tham gia đi đúng luật. Nếu chỉ sử dụng các hộp giới hạn sẽ không thể xác định được độ lớn của vật cản cũng như độ lớn của biển báo và đèn tín hiệu giao thông, điều này cũng sẽ không giúp ích nhiều trong việc xác định và đưa ra các quyết định kịp thời khi tham gia giao thông. Nhận thấy được tầm quan trọng của các vấn đề trên, phần mềm NogiCargo đã xây dựng một tính năng là nhận diện đèn tín hiệu và biển báo giao thông nhằm hỗ trợ cho việc điều khiển tự động trên ô tô tuân thủ đúng luật lệ và an toàn hơn trong quá trình tham gia giao thông.
1.2 Các giải pháp hiện tại và hạn chế Phát hiện biển báo và đèn tín hiệu giao thông là một trong những vấn đề rất quan trọng trong nhiều ứng dụng về các hệ thống hỗ trợ giao thông tự động, đặc biệt trong các hệ thống điều khiển xe tự động. Trong khoảng từ năm 1998 đến nay, cùng với sự phát triển vượt bậc về tốc độ xử lý của máy tính, giá thành của các thiết bị hỗ trợ ngày càng giảm thì các nghiên cứu về hệ thống điều khiển xe tự động ngày càng được phát triển. Đã có nhiều nghiên cứu tập trung vào bài toán phát hiện biển báo, đèn tín hiệu giao thông và một số kết quả bước đầu đạt được đã cho thấy những tín hiệu khả quan. Trong bài toán phát hiện biển báo và đèn tín hiệu giao thông có 2 loại mục tiêu chính là:
Nhận dạng các loại đèn tín hiệu và một số loại biển báo giao thông phổ biến Đưa ra thông báo để hỗ trợ con người trong quá trình lái xe, điều khiển xe tự động Trong đó, mục tiêu phục vụ cho hệ thống điều khiển xe tự động được đánh giá là khó nhất. Có khá nhiều nghiên cứu trong thời gian gần đây tập trung ở mục tiêu hỗ trợ hệ thống điều khiển xe tự động, tuy vậy vẫn còn nhiều khó khăn tồn tại trong việc giải quyết bài toán với mục tiêu này nói riêng cũng như toàn bộ bài toán phát hiện biển báo và đèn tín hiệu giao thông nói chung. Các khó khăn có thể chỉ ra như sau:
Phần lớn yêu cầu đòi hỏi ứng dụng phải xử lý ở thời gian thực. Trong rất nhiều nghiên cứu chỉ ra các kết quả đạt được khá tốt, tuy nhiên các nghiên cứu này vẫn chưa thực thi được trong thời gian thực Khó khăn nhận diện chính xác khi vị trí các đối tượng bị che khuất Sự phức tạp của địa hình, thời tiết, các vật thể gây nhiễu...
Hiện nay, có rất nhiều hệ thống phát hiện biển báo và đèn tín hiệu giao thông với độ chính xác cao, điển hình là hệ thống phát hiện biển báo và đèn tín hiệu giao thông sử dụng mô hình Mask R-CNN. Tuy nhiên tốc độ xử lý của mô hình này lại rất chậm, chỉ khoảng 7 khung hình/ giây. Điều này là một cản trở rất lớn trong việc 3áp dụng vào những bài toán phát hiện biển báo và đèn tín hiệu giao thông thực tế yêu cầu tốc độ xử lý phải trên 30 khung hình/giây.
1.3 Mục tiêu và định hướng giải pháp Trong phần mềm NogiCargo, chúng ta sẽ tập trung vào vấn đề xử lý thời gian.
Vậy làm sao để tốc độ xử lý đạt được thời gian thực? Vấn đề mà các mô hình trước đó gặp phải là tính ‘tuần tự’ trong các bước tính toán. Để giải quyết vấn đề này, chúng ta phải tìm hiểu một thuật toán có các bước tính toán được thực hiện song song nhau, và bỏ qua hoặc thay đổi những bước không quan trọng, có thể thay đổi để giảm bớt thời gian thực thi tính toán trong mô hình.YOLO là một phương pháp phát hiện đối tượng thời gian thực hiện đại nhất hiện nay. Với GPU Titan X mô hình YOLO có tốc độ 30 FPS với độ chính xác trung bình 57.9% trên tập dữ liệu tiêu chuẩn COCO. YOLO rất phù hợp cho các bài toán đòi hỏi tốc độ xử lý theo thời gian thực như giám sát giao thông, xe tự lại, các hệ thống giám sát an ninh. Vì vậy hệ thống đã áp dụng thuật toán YOLO vào việc nhận dạng đèn tín hiệu và biển báo giao thông.
42.1 Ngữ cảnh của bài toán 2.1.1 Khái niệm học sâu Học sâu (deep learning) là một nhánh của ngành máy học, dựa trên một tập hợp các thuật toán để cố gắng mô hình dữ liệu để trừu tượng hóa ở mức cao bằng cách sử dụng nhiều lớp xử lý với cấu trúc phức tạp, hoặc bằng cách khác bao gồm nhiều lớp biến đổi phi tuyến để trích tách đặc trưng và chuyển đổi. Mỗi lớp kế tiếp dùng đâu ra của lớp trước làm đầu vào. Các thuật toán này có thể được giám sát hoặc không cần giám sát và các ứng dụng bao gồm các mô hình phân tích (không giám sát) và phân loại (giám sát). Một trong những phương pháp học sâu thành công nhất là mô hình mạng nơ-ron nhân tạo (Arificial Neural Network). Mạng nơ-ron nhân tạo được lấy cảm hứng từ các mô hình sinh học năm 1959 được đề xuất bởi người đoạt giải Nobel David H. Hubel Torsten Wiesel, 2 người đã tìm thấy hai loại tế bào trong vỏ não thị giác chính: các tế bào đơn giản và các tế bào phức tạp.
Nhiều mạng nơ-ron nhân tạo có thể được xem như là các mô hình ghép tầng của các tế bào loại lấy cảm hứng từ những quan sát sinh học.
Hình 2.1: Tế bào sinh học Mạng neural học sâu là một mô hình mạng neural có nhiều tầng kết hợp với nhau. Mỗi tầng mạng là đầu ra của tầng trước và là đầu vào của tầng sau.
Độ sâu của mô hình được tính bằng số tầng ẩn cộng một.
5Hình 2.2: Kiến trúc mạng nơ-ron gồm k tầng ẩn Kiến trúc chung của mạng nơ-ron nhân tạo bao gồm thành phần: Tầng đầu vào, Tầng ẩn và Tầng đầu ra.
Tầng đầu vào (Input layer): Là nơi để nạp dữ liệu vào. Mỗi nơ-ron tương ứng với một thuộc tính (attribute) hoặc đặc trưng (feature) của dữ liệu đầu vào.
Tầng ẩn (Hidden layer): Là nơi xử lý dữ liệu trước khi đưa ra output. Thường là hàm tổng (Summation function) để đưa ra giá trị của một nơ-ron tại hidden layer. Có thể có nhiều hơn một hidden layer. Khi đó đầu ra của một hidden layer sẽ là đầu vào cho hidden layer tiếp theo.
Lớp đầu ra (Output layer): Là giá trị đầu ra của mạng nơ-ron. Sau khi đi qua hidden layer cuối cùng, dữ liệu sẽ được chuyển hóa bằng một hàm số được gọi là hàm kích hoạt (Activation function) và đưa ra output cuối cùng. Hàm chuyển đổi thường là hàm tanh(x), sigmoid(x) hoặc softmax(x).
Cập nhật trọng số: Trong mạng nơ-ron, trọng số được cập nhật như sau:
Bước 1: Lấy một batch dữ liệu huấn luyện.
Bước 2: Thực hiện việc lan truyền tiến để lấy được lỗi tương ứng.
Bước 3: Lan truyền ngược lỗi để lấy được gradients.
Bước 4: Sử dụng gradients để cập nhật trọng số của mạng.
2.1.2 Một số thuật ngữ trong mạng nơ-ron Hàm softmax: Bước softmax có thể được coi là một hàm logistic tổng quát lấy đầu vào là một vec-tơ chứa các giá trị x∈Rnvà cho ra là một vec-tơ gồm các xác suấtp∈Rnthông qua một hàm softmax ở cuối kiến trúc. Nó được định nghĩa như sau:
6Hàm lỗi (Cross-Entropy): Trong bối cảnh của mạng neural, hàm lỗi cross-entropy L(z,y) thường được sử dụng và định nghĩa như sau:
L(z, y) = −[ylog(z) + (1−y)log(1−z)] Hàm kết hợp Softmax CrossEntropy : là sự kết hợp của lớp fully connected cuối cùng.
khi là η, chỉ ra tốc độ mà trọng số được cập nhật. Thông số này có thể là cố định hoặc được thay đổi tuỳ biến. Phương thức phổ biến nhất hiện tại là Adam, trong đó phương thức thay đổi tốc độ học một cách phụ hợp nhất có thể.
Hàm kích hoạt (Activation function): Hàm kích hoạt được sử dụng ở phần cuối của đơn vị ẩn để đưa ra độ phức tạp phi tuyến tính cho mô hình và được sử dụng làm dữ liệu đầu vào cho tầng tiếp theo.
Hàm kích hoạt có 3 loại:
Hàm kích hoạt tuyến tính (Linear Activation Function) Hàm kích hoạt nhị phân (Binary Step Function) Hàm kích hoạt phi tuyến (non-Linear Activation Function) Hàm kích hoạt tuyến tính: là một hàm có dang f(x) = cx. hàm này sử dụng tích ố giữa đầu vào và trọng số của mỗi nơ-ron và tạo ra một tín hiệu đầu ra tỉ lệ với đầu vào. Nhước điểm của hàm tuyến tính gồm 2 vấn đề:
Không thể sử dụng lan truyền ngược để đào tạo mô hình vì đạo hàm của hàm này là một hằng số nên không thể có mối liên hệ với đầu vào.
Nó chỉ có chức năng như một hàm hồi quy tuyến tính, vì vậy sẽ hạn chế trong việc tính toán và xử lý các thông số phức tạp của dữ liệu đầu vào.
Hàm kích hoạt nhị phân: là một hàm kích hoạt dựa trên ngưỡng. Nếu một giá trị đầu vào cao hơn hoặc thấp hơn một ngưỡng cho trước, mạng nơ-ron sẽ được kích hoạt và gửi tính hiệu chính xác đến lớp tiếp theo. Đầu ra của hàm kích hoạt nhị phân chỉ có hai giá trị. Vị vậy trong một số bài toán đa chiều thì hàm này không thể giải quyết được.
Hàm kích hoạt phi tuyến: là một hàm cho phép mô hình tạo ra ánh xạ giữa đầu vào và đầu ra của mạng. Điều này phù hợp cho việc đâof tạo các mô hình phức tạp của các tập dữ liệu phi tuyến có kích thước lớn. Phù hợp sử dụng lan truyền ngược để cập nhật các trọng số của mô hình.
Dưới đây là một số hàm kích hoạt phi tuyến thường dùng:
7Hình 2.3: Một số hàm kích hoạt phi tuyến phổ biến  Tỷ lệ IoU (Intersection over Union): Tỷ lệ vùng giao trên vùng hơp, là một hàm Hình 2.4: Ví dụ về IoU  Hộp mỏ neo (Anchor boxes): đây là một kỹ thuật được dùng để dự đoán những hộp giới hạn nằm chồng lên nhau. Trong thực nghiệm, mạng được phép dự đoán nhiều hơn một hộp giới hạn cùng một lúc, trong đó mỗi dự đoán được giới hạn theo một tập những tính chất hình học cho trước. Ví dụ, dự đoán đầu tiên là một hình chữ nhật ngang, và dự đoán thứ hai có thể là một hình chữ nhật đứng hay một hình có kích thước hình học khác.
Anchors là sự sắp xếp độ ưu tiên bouding box, mà chúng ta tính toán trên tập dữ liệu sử dụng k-mean. Chúng ta sẽ dự đoán độ rộng và chiều cao của hộp từ cụm trung tâm. Tọa độ điểm trung tâm của hộp liên quan tới vị trí của phần lọc đã được dự đoán sử dụng hàm sigmoid.
8Theo công thức mô tả các đầu ra mạng được biến đổ để bắt buộc dự đoán bouding box:
Hình 2.5: Xác định các mỏ neo và hộp dự đoán Ở đây bx, by, bw, bhlà tọa độ trung tâm x,y, chiều rộng và chiều cao của hộp dự đoán. tx, ty, tw, thlà đầu ra của mạng. cxvàcylà tọa độ của lưới ô. pwvàphlà chiều của hộp. Công thức tình các giá trị trên:
bw=pwetw bh=pheth Tọa độ trung tâm Chúng ta dự đoán tọa độ trung tâm thông qua hàm sigmoid.
Điều này bắt buộc giá trị của đầu ra phải nằm giữa [0, 1].
Non-max suppression: Đây là một kỹ thuật hướng tới việc loại bỏ những hộp giới hạn bị trùng lặp được chồng lên nhau của cùng một đối tượng bằng cách chọn hộp chứa nhiều đặc trưng nhất và loại bỏ những hộp giới hạn khác.
Upsampling: là tích chập ngược. Một cách khác để kết nối đầu ra thô với các pixel dày đặc là nội suy. Ví dụ, phép nội suy song tuyến tính đơn giản tính toán 9từng đầu ra từ bốn đầu vào gần nhất bằng một bản đồ tuyến tính chỉ phụ thuộc vào vị trí tương đối của các ô đầu vào và đầu ra. Theo một nghĩa nào đó, upampling với yếu tố f là tích chập với bước tiến đầu vào phân đoạn là 1/f. Vì vậy, miễn f là tích phân, do đó, một cách tự nhiên để lấy mẫu là tích chập ngược (đôi khi được gọi là giải mã) với bước tiến đầu ra là f . Một hoạt động như vậy là không đáng kể để thực hiện, vì nó chỉ đơn giản là đảo ngược các bước tiến và lùi của tích chập.
Do đó, việc lấy mẫu được thực hiện trong mạng để học từ đầu đến cuối bằng cách truyền ngược từ mất pixel.
Hình 2.6: Ví dụ về Upsampling Mục đích của hàm này là tăng kích thước cho bức ảnh nhằm giảm mất mát và tính gần đúng các giá trị pixel bị thiếu.
Các bước thực hiện:
Đầu tiên, tăng kích thước hình ảnh lên gấp đôi hình ảnh gốc ở mỗi chiều, với các hàng chẵn mới Thực hiện phép chập với cùng một bộ số nhân được hiển thị ở trên để tính gần đúng giá trị của "pixel bị thiếu" Upsampling dựa trên lý thuyết về hình ảnh của kim tự tháp. Tức là một tập hợp các hình ảnh xuất phát từ một hình ảnh gốc được lấy mẫu liên tiếp cho đến khi đạt được một số điểm dừng mong muốn. Phương pháp upsamping dựa trên loại hình Kim tự tháp Laplacian - Được sử dụng để tái tạo một hình ảnh được lấy mẫu từ một 10hình ảnh nhỏ hơn trong kim tự tháp.
2.1.3 Mạng nơ-ron tích chập – Convolutional neural network (CNN) Mạng neural tích chập là mô hình mạng neural hoạt động hiểu quả dựa trên dữa liệu ảnh nhờ khả năng nhận diện tốt các đường nét đặc trưng của đối tượng trong ảnh.
Hình 2.7: Thành phần một mạng nơ-ron tích chập  Mạng Neural tích chập gồm 3 tầng chính:
Tầng tích chập (CONV): sử dụng các bộ lọc để thực hiện phép tích chập khi đưa chúng đi qua đầu vào I theo các chiều của nó. Các siêu tham số của các bộ lọc này bao gồm kích thước bộ lọc F và độ trượt (stride) S. Kết quả đầu ra O được gọi là feature map hay activation map.
Hình 2.8: Tầng Convolution  Tầng Pooling (POOL): là một phép downsampling, thường được sử dụng sau tầng tích chập, giúp tăng tính bất biến không gian. Cụ thể, max pooling và average pooling là những dạng pooling đặc biệt, mà tương ứng là trong đó giá trị lớn nhất và giá trị trung bình được lấy ra.
11Hình 2.9: Tầng Pooling  Tầng Fully Connected (FC): nhận đầu vào là các dữ liệu đã được làm phẳng, mà mỗi đầu vào đó được kết nối đến tất cả neuron. Trong mô hình mạng CNNs, các tầng kết nối đầy đủ thường được tìm thấy ở cuối mạng và được dùng để tối ưu hóa mục tiêu của mạng ví dụ như độ chính xác của lớp.
Hình 2.10: Tầng Fully Connected  2.2 Các kết quả nghiên cứu tương tự Trong phần này em xin phép trình bày về một số thuật toán phổ biến liên quan đến bài toán phát hiện đối tượng và những hạn chế của chúng.
2.2.1 Mô hình R-CNN R-CNN là một thuật toán phát hiện vật thể mà đầu tiên phân chia ảnh thành các vùng để tìm các hộp giới hạn có khả năng liên quan cao rồi chạy một thuật toán phát hiện để tìm những thứ có khả năng cao là vật thể trong những hộp giới hạn đó.
Ý tưởng thuật toán R-CNN khá đơn giản, gồm 2 bước:
Bước 1: Dùng Selective Search algorithm để lấy ra khoảng 2000 bounding box trong input mà có khả năng chứa đối tượng.
Bước 2: Với mỗi bounding box ta xác định xem nó là đối tượng nào (người, ô tô, xe đạp,. . . ) 12Hình 2.11: Các bước thực hiện thuật toán R-CNN  Selective search algorithm: Input của thuật toán là ảnh màu, output là khoảng 2000 bounding box mà có khả năng chứa các đối tượng.
Hình 2.12: Đầu vào và đầu ra thuật toán Selective search algorithm  Nhận xét: Ta không thể dùng mỗi màu trong output để làm 1 region proposal được vì:
Mỗi đối tượng trong ảnh có thể chứa nhiều hơn 1 màu.
Các đối tượng bị che mất một phần như cái đĩa dưới cái chén không thể xác định được.
Cần nhóm các vùng màu với nhau để làm region proposal.
Phân loại region proposal: Bài toán trở thành phân loại ảnh cho các region proposal. Do thuật toán selective search cho tới 2000 region proposal nên có rất nhiều region proposal không chứa đối tượng nào. Vậy nên ta cần thêm 1 lớp hình ảnh nền (không chứa đối tượng nào). Ví dụ như hình dưới ta có 4 region proposal, ta sẽ phân loại mỗi bounding box là người, ngựa hay hình ảnh nền.
13Hình 2.13: Các bước xử lý hình ảnh để lấy region proposal  Sau đó các region proposal được resize lại về cùng kích thước và thực hiện transfer learning với feature extractor, sau đó các extracted feature được cho vào thuật toán SVM để phân loại ảnh.
Bên cạnh đó thì extracted feature cũng được dùng để dự đoán 4 offset values cho mỗi cạnh. Ví dụ như khi region proposal chứa người nhưng chỉ có phần thân và nửa mặt, nửa mặt còn lại không có trong region proposal đó thì offset value có thể giúp mở rộng region proposal để lấy được toàn bộ người.
Đánh giá R - CNN: Hồi mới xuất hiện thì thuật toán hoạt động khá tốt cho với các thuật toán về computer vision trước đó nhờ vào CNN, tuy nhiên nó vẫn có khá nhiều hạn chế:
Vì với mỗi ảnh ta cần phân loại các class cho 2000 region proposal nên thời gian train rất lâu.
Không thể áp dụng cho real-time vì mỗi ảnh trong test set mất tới 47s để xử lý.
2.2.2 Mô hình Fast R-CNN Fast R-CNN được giới thiệu vào năm 2015. Fast R -CNN giải quyết được một số hạn chế của R-CNN để cải thiện tốc độ. Bằng việc xử lý tất cả các vùng được đề xuất cùng nhau trong CNN bằng cách sử dụng lớp ROI Pool. Tương tự như R-CNN thì Fast R-CNN vẫn dùng selective search để lấy ra các region proposal.
Tuy nhiên là nó không tách 2000 region proposal ra khỏi ảnh và thực hiện bài toán image classification cho mỗi ảnh. Fast R-CNN cho cả bức ảnh vào ConvNet (một vài convolutional layer + max pooling layer) để tạo ra convolutional feature map.
Sau đó các vùng region proposal được lấy ra tương ứng từ convolutional feature map. Tiếp đó được Flatten và thêm 2 Fully connected layer (FCs) để dự đoán lớp của region proposal và giá trị offset values của bounding box.
14Hình 2.14: Hình ảnh minh hoạ thuật toán Fast R - CNN Fast R-CNN khác với R-CNN là nó thực hiện feature map với cả ảnh sau đó với lấy các region proposal ra từ feature map, còn R-CNN thực hiện tách các region proposal ra rồi mới thực hiện CNN trên từng region proposal. Do đó Fast R-CNN nhanh hơn đáng kể nhờ tối ưu việc tính toán bằng Vectorization ( biểu diều bài toán dưới dạng vector ).
Tuy nhiên nhìn hình trên ở phần test time với mục Fast R-CNN thì thời gian tính region proposal rất lâu và làm chậm thuật toán.
=> Cần thay thế thuật toán selective search. Giờ người ta nghĩ đến việc dùng deep learning để tạo ra region proposal →Faster R-CNN ra đời.
2.2.3 Mô hình Faster R-CNN Faster R-CNN được giới thiệu vào đầu năm 2017.Đây là một bước tiến xa hơn khi thực hiện bước đề xuất vùng cách sử dung ConvNet có tên là Region Prốpal Network (RPN). Faster R-CNN không dùng thuật toán selective search để lấy ra các region proposal, mà nó thêm một mạng CNN mới gọi là RPN để tìm các region proposal.
15Hình 2.15: Kiến trúc của mang Faster R-CNN Đầu tiên cả bức ảnh được cho qua pre-trained model để lấy feature map. Sau đó feature map được dùng cho Region Proposal Network để lấy được các region proposal. Sau khi lấy được vị trí các region proposal thì thực hiện tương tự Fast R-CNN.
Region Proposal Network (RPN):Input của RPN là feature map và output là các region proposal. Ta thấy các region proposal là một hình chữ nhật.
Hình 2.16: Cách lấy toạ độ một bức ảnh 16Mà một hình chữ nhật được xác định bằng 2 điểm ở 2 góc, ví dụ A( xmin, ymin) và B( xmax, ymax). Nhận xét: Khi RPN dự đoán ta phải rằng buộc xmin<xmaxvà ymin<ymax. Hơn nữa các giá trị x,y khi dự đoán có thể ra ngoài khỏi bức ảnh => Cần một kĩ thuật mới để biểu diễn region propsal →Anchor ra đời. Ý tưởng là thay vì dự đoán 2 góc ta sẽ dự đoán điểm trung tâm ( xcenter , ycenter ) và width, height của hình chữ nhật. Như vậy mỗi anchor được xác định bằng 4 tham số ( xcenter , ycenter , width, height). Vì không sử dụng Selective search nên RPN ban đầu cần xác định các anchor box có thể là region proposal, sau đó qua RPN thì chỉ ouput những anchor box chắc chắn chứa đối tượng.
Hình 2.17: Xác đinh tâm của bức ảnh bằng RPN  Ảnh bên trái kích thước 400 * 600 pixel, tác tâm của anchor box màu xanh, cách nhau 16 pixel →có khoảng (400*600)/(16*16) = 938 tâm. Do các đối tượng trong ảnh có thể có kích thước và tỉ lệ khác nhau nên với mỗi tâm ta định nghĩa 9 anchors với kích thước 64x64, 128x128, 256x256, mỗi kích thước có 3 tỉ lệ tương ứng:1 :
1, 1 : 2 và 2 : 1. Giống như hình bên phải với tâm ở giữa 3 kích thước ứng với màu da cam, xanh lam, xanh lục và với mỗi kích thước có 3 tỉ lệ. →Số lượng anchor box giờ là 938 9 = 8442 anchors. Tuy nhiên sau RPN ta chỉ giữ lại khoảng 1000 anchors box để thực hiện như trong Fast R-CNN.
Việc của RPN là lấy ra các region proposal giống như selective search chứ không phải là phân loại ảnh. Mô hình RPN khá đơn giản, feature map được cho qua Conv layer 3*3, 512 kernels. Sau đó với mỗi anchor lấy được ở trên, RPN thực hiện 2 bước:
Dự đoán xem anchor đấy là foreground (chứa đối tượng) hay hình ảnh nền (không chứa đối tượng) Dự đoán 4 offset value cho xcenter , ycenter , width, height cho các anchor Sau cùng dựa vào phần trăm dự đoán background RPN sẽ lấy N anchor (N có thể 2000, 1000, thậm chí 100 vẫn chạy tốt) để làm region proposal.
172.2.4 Mô hình SSD(Single Shot Detector) Hình 2.18: Mô hình mạng SSD  SSD đạt được sự cân bằng tốt giữa tốc độ và độ chính xác. SSD chỉ chạy một mạng CNN trên hình ảnh đầu vào một lần và tính toán một bản đồ các đặc trưng.
Bây giờ chúng ta chạy một filter có kích thước nhỏ 3x3 trên toàn bộ bản đồ đặc trưng này để dự đoán các hộp giới hạn và xác suất phân loại. SSD cũng sử dụng các hộp neo ở các tỷ lệ khung hình khác nhau tượng tự như Faster R-CNN. Để xử lý tỷ lệ, SSD dự đoán các hộp giới hạn sau nhiều lần co dãn.
2.2.5 Kết luận chương Qua phần giới thiệu và đánh giá ở trên chúng ta có rất nhiều phương pháp để phát hiện phương tiện giao thông. Nhưng do tốc độ di chuyển của các phương tiện giao thông thường cao nên cần một phương pháp có tốc độ xử lý nhanh và độ chính xác tốt trong điều kiện ánh sáng tốt.
183.1 Bài toán nhận diện biển báo và đèn tín hiệu giao thông 3.1.1 Tổng quan bài toán Nhận diện biển báo và đèn tín hiệu giao thông là một bài toán khó và phức tạp khi cần xác định vị trí và phân loại các loại biển báo và đèn tín hiệu giao thông. Hệ thống này bao gồm ba bước xử lý chính:
1. Thu nhận ảnh từ các hệ thống camera giao thông và thực hiện tiền xử lý dữ liệu đầu vào.
2. Sử dụng một mô hình phát hiện đã được huấn luyện để phát hiện (YOLO, R CNN, SSD. . . ) và trả về kết quả bao gồm hộp giới hạn và đối tượng xuất hiện trong các hộp giới hạn đó.
3. Thực hiện hậu xử lý để loại bỏ các hộp chồng chéo, theo dõi các loại biển báo, đèn tín hiệu. . .
3.1.2 Các điều kiện ràng buộc Để thu được kết quả phát hiện chính xác cao các hệ thống camera cần được đặt tại các vị trí phù hợp như giữa trục đường chính để có góc nhìn rộng tránh các trường hợp các biển báo hay đèn tín hiệu bị che khuất, các vị trí có ánh sáng tốt.
Các hệ thống xử lý trung tâm cần được hỗ trợ các máy tính xử lý có nhiều CPU hoặc GPU giúp cho việc phát hiện các biển báo, đèn tín hiệu nhanh và chính xác đảm bảo thời gian thực.
3.2 Hệ thống phát hiện đối tượng thời gian thực YOLO 3.2.1 Tổng quan hệ thống phát hiện đối tượng YOLO.
YOLO là một phương pháp phát hiện đối tượng thời gian thực hiện đại nhất hiện nay. Với GPU Titan X mô hình YOLO có tốc độ 30 FPS với độ chính xác trung bình 57.9% trên tập dữ liệu tiêu chuẩn COCO. YOLO rất phù hợp cho các bài toán đòi hỏi tốc độ xử lý theo thời gian thực như giám sát giao thông, xe tự lại, các hệ thống giám sát an ninh.
193.2.2 Kiến trúc của mô hình YOLO qua các phiên bản a, YOLO version 1 Hình 3.1: YOLO version 1  YOLOv1 có 24 lớp convolutional theo sau là 2 lớp fully connected (FC). Một vài lớp convolutional sử dụng các lớp giảm có kích thước 1x1 để giảm độ sâu của các features map. Đối với lớp convolutional cuối cùng, nó xuất ra một tensor có kích thước (7x7x1024). Tensor sau đó được dàn phẳng ra. Sử dụng 2 fully connected dưới dạng hồi quy tuyến tính tạo ra output có kích thước 7x7x30 tương ứng với dự đoán 2 hộp giới hạn cho mỗi ô và 20 lớp dự đoán như ví dụ trên.
b, YOLO version 2 Để cải thiện độ chính xác YOLOv2 đã thực hiện cải tiến các phương pháp sau Loại bỏ các lớp fully connected chịu trách nhiệm dự đoán hộp giới hạn Hình 3.2: Loại bỏ phần kết nối đầy đủ trên YOLOv2  YOLO di chuyển lớp dự đoán từ cấp độ ô lên cấp độ hộp giới hạn. Bây giờ mỗi dự đoán bao gồm 4 tham số cho hộp giới hạn, 1 điểm tin cậy của hộp và C xác suất lớp, tức là với 5 hộp giới hạn với 25 tham số cho mỗi hộp giới hạn ta có 125 tham số cho mỗi ô.
20Hình 3.3: Kết quả dự đoán của YOLO Để tạo ra các dự đoán với kích thước 7x7x125, chúng ta sẽ thay thế lớp convolutional cuối cùng bằng ba filter có kích thước 3x3 cho mỗi đầu ra có 1024 giá trị. Sau đó lớp convolutional cuối cùng ta áp dụng filter có kích thước 1x1 để chuyển từ 7x7x1024 output về 7x7x125.
Thay đổi kích thước ảnh đầu vào từ 448x448 xuống 416x416 Loại bỏ một lớp pooling để làm cho đầu ra của mạng có kích thước 13x13 (thay vì 7x7) c, YOLO version 3 YOLOv3 sử dụng một biến thể của Darknet[25, 26], ban đầu có 53 lớp được đào tạo trên Imagenet. Đối với nhiệm vụ phát hiện, 53 lớp khác được xếp chồng lên nó, tạo cho chúng ta một kiến trúc cơ bản hoàn toàn dựa trên 106 lớp cho YOLOv3 Hình 3.4: Mô hình YOLO version 3 Hình dạng kernel của phát hiện là 1x1x(Bx(5+C)). Ở đây B là số lượng hộp giới hạn một ô trên ma trậ đặc trưng có thể dự đoán, 5 là thuộc tính của hộp giới hạn 21và điểm tin cậy và C là số lớp. Ma trậ đặc trưng được tạo ra bi kernel này có chiều rộng và chiều cao giống hệt nhau của ma trậ đặc trưng trước đó và có các thông tin dọc theo chiều sâu như mô tả hình bên dưới Hình 3.5: Kết quả dự đoán của YOLOv3 d, YOLO version 4 YOLOv4 áp dụng ý tưởng của CSPBlock, thay thế Residual Block thông thường của YOLOv3 thành CSPResBlock, đồng thời đổi activation function từ LeakyReLU thành Mish, tạo nên CSPDarkNet53.
Trong các bài Classification, ở layer cuối ta thường hay sử dụng DropOut để làm giảm hiện tượng Overfitting. Nhưng trong Convolution thì việc bỏ đi random một số vị trí ở trong feature map có vẻ không hợp lý lắm. Vì các vị trí ở cạnh nhau trong feature map có tương quan cao với nhau, nên việc bỏ đi các vị trí một cách random dường như sẽ không đem lại nhiều hiệu quả. DropBlock sẽ bỏ đi nhóm vị trí trong feature map thay vì chỉ bỏ đi một vị trí Cũng giống YOLOv3, YOLOv4 có thêm neck để thực hiện phát hiện vật thể ở trên những scale khác nhau. YOLOv4 sử dụng 2 thành phần cho neck: SPP và PAN.
YOLOv4 áp dụng Label Smoothing trong việc classfication cho vật thể. Ý tưởng về Label Smoothing lần đầu được giới thiệu trong Inception-v2. Việc này làm giảm 22sự tự tin thái quá của model khi dự đoán một class, từ đó giảm nhẹ overfitting của model.
e, YOLO version 5 YOLOv5 là một phần mở rộng tự nhiên của YOLOv3 PyTorch bởi Glenn Jocher . Kho lưu trữ YOLOv3 PyTorch là điểm đến phổ biến cho các nhà phát triển để chuyển các trọng số YOLOv3 Darknet sang PyTorch và sau đó chuyển sang sản xuất. Những cải tiến này ban đầu được gọi là YOLOv4 nhưng do việc phát hành gần đây của YOLOv4 trong khuôn khổ Darknet, để tránh xung đột phiên bản, nó đã được đổi tên thành YOLOv5.
Thuật toán YOLOv5 về cơ bản cũng thừa kế các phương pháp cơ bản của các YOLO, tuy nhiên YOLOv5 áp dụng một số thuật toán phát hiện vật thể nhanh, tối ưu hóa các phép toán thực hiện song song giúp tăng tốc độ nhận diện và giảm thời gian huấn luyện một cách tối ưu.
f, Cấu trúc nhận diện vật thể của YOLOv5 Cấu trúc nhận diện vật thể của YOLOv5 thường có 3 phần được thể hiện ở hình been duowsi.
Hình 3.6: Cấu trúc nhận diện vật thể của YOLOv5 Backbone: Backbone là 1 mô hình pre-train của 1 mô hình học chuyển (transfer learning) khác để học các đặc trưng và vị trí của vật thể. Các mô hình học chuyển thường là VGG16, ResNet-50,...
Head: Phần head được sử dụng để tăng khả năng phân biệt đặc trưng để dự đoán class và bounding-box. Ở phần head có thể áp dụng 1 tầng hoặc 2 tầng:
–Tầng 1: Dense Prediction, dự đoán trên toàn bộ hình với các mô hình RPN, YOLO, SSD,...
–Tầng 2: Sparse Prediction dự đoán với từng mảng được dự đoán có vật thể với các mô hình R-CNN series,..
Neck: Ở phần giữa Backbone và Head, thường có thêm một phần Neck. Neck thường được dùng để làm giàu thông tin bằng cách kết hợp thông tin giữa quá trình bottom-up và quá trình top-down (do có một số thông tin quá nhỏ khi đi 23qua quá trình bottom-up bị mất mát nên quá trình top-down không tái tạo lại được).
g, Đặc điểm của YOLOv5 với các phiên bản trước của YOLO Vì YOLOv5 được triển khai trong PyTorch ban đầu nên nó được hưởng lợi từ hệ sinh thái PyTorch đã được thiết lập: hỗ trợ đơn giản hơn và triển khai dễ dàng hơn. Hơn nữa, là một khung nghiên cứu được biết đến rộng rãi hơn, việc lặp lại trên YOLOv5 có thể dễ dàng hơn cho cộng đồng nghiên cứu rộng lớn hơn. Điều này cũng làm cho việc triển khai đến các thiết bị di động đơn giản hơn vì mô hình có thể được biên dịch sang ONNX và CoreML một cách dễ dàng.
Khả năng đào tạo cũng như khả năng suy luận rất là nhanh, độ chính xác cao.
Cuối cùng YOLOv5 có dung lượng nhỏ. Cụ thể, một tệp trọng số cho YOLOv5 là 27 megabyte. Tệp trọng số cho YOLOv4 (với kiến trúc Darknet) là 244 megabyte.
YOLOv5 nhỏ hơn gần 90% so với YOLOv4. Điều này có nghĩa là YOLOv5 có thể được triển khai cho các thiết bị nhúng dễ dàng hơn nhiều.
244.1 Chuẩn bị bộ Dataset Bộ dữ liệu được sử dụng trong bài toán phát hiện biển báo và đèn tín hiệu giao thông sử dụng mô hình thuật toán YOLO bao gồm 7500 hình ảnh về đèn tín hiệu và biển báo giao thao của nhiều bộ dữ liệu khác nhau được thu thập trong nhiều điều kiện khác nhau. Traffic Light dataset là bộ dữ liệu đèn tín hiệu giao thông của Trung Quốc, bao gồm 3000 ảnh được chụp ở các điều kiện khác nhau và các cung đường khác nhau. Bộ dữ liệu biển báo giao thông Việt Nam thu thập từ các camera hành trình chứa 4500 hình ảnh và được phân loại theo 7 loại chính: cấm ngược chiều, cấm dừng và đỗ, cấm rẽ, giới hạn tốc độ, nguy hiểm, hiệu lệnh và một vài loại biển báo còn lại.
Hình 4.1: Bộ dữ liệu thu thập được Với lượng dữ liệu hình ảnh trên, đây là một bộ dữ liệu không hề ít, ở lần thử đầu tiên train thuật toán YOLOv5 với bộ dữ liệu này, mô hình cho kết quả như sau:
Ở điều kiện thời tiết tốt, trời sáng, các biển báo hay đèn tín hiệu nằm ở vị trí thuận lợi, mô hình đem lại kết quả với độ chính xác khá cao, nhận diện được hầu hết các đối tượng cần thiết trong ảnh.
25Hình 4.2: Kết quả thu được ở điều kiện tốt Ở các điều kiện thời tiết xấu (trời mưa, nắng quá to,...), ánh sáng môi trường kém(quá tối hoặc quá sáng), các biển báo bị mờ hoặc chụp ở góc nghiêng,...
thì mô hình đem lại kết quả không quá cao, thậm chí đa số sẽ không nhận diện được hoặc nhận diện sai các đối tượng biển báo hay đèn tín hiệu.
Hình 4.3: Kết quả thu được ở điều kiện sương mù Dễ dàng nhận ra vấn đề khi thực hiện train thuật toán YOLOv5 với tập dữ liệu nguyên gốc ban đầu: Kết quả huấn luyện có độ chính xác rất cao trên tập huấn luyện và tập kiểm tra. Nhưng khi áp dụng vào thực tế với đầu vào được ghi lại ở nhiều điều kiện khác nhau, thuật toán cho độ chính xác rất thấp. Qua quá trình tìm hiểu, em nhận ra những nguyên nhân chính dẫn đến vấn đề kết qu không như mong đợi này đó là:
Đặc thù bài toán hỗ trợ con người trong quá trình lái xe nói chung và bài toán nhận diện biển báo, đèn tín hiệu giao thông nói riêng, yêu cầu thực hiện trong mọi loại môi trường thời tiết, mọi loại địa hình, mọi thời điểm trong ngày. Đặc 26biệt càng trong điều kiện khó khăn trong quan sát thì càng yêu cần hệ thống phải hỗ trợ ở mức tốt nhất cho con người. Ví dụ một người lái xe dưới trời mưa, lượng mưa ngoài trời sẽ ảnh hưởng khá lớn đến tầm nhìn các biển báo giao thông; khi lái xe dưới thời tiết quá nắng, ánh nắng đôi khi gây chói mắt và ảnh hưởng đến việc quan sát biển báo; hoặc lái xe vào buổi đêm, tài xế dễ bị buồn ngủ dẫn đến không để ý các biển báo, đèn tín hiệu trên đường,...Những lúc này hệ thống hỗ trợ đưa ra những cảnh báo, nhắc nhở sẽ là một tính năng vô cùng hữu ích. Vì vậy để hệ thống hỗ trợ con người đem lại sự khả dụng cao nhất, thì yêu cầu hệ thống này phải chạy được ở trong nhiều loại điều kiện, nhắt là những điều kiện khó khăn. Nếu chỉ chạy được ở trong những điều kiện tốt, hoặc chỉ trong điều kiện xấu, thì tính khả dụng xem như bằng không.
Bộ dữ liệu ảnh ở trên tuy lớn nhưng lại gặp một số vấn đề sau:
–Đa số ảnh chụp vào ban ngày, lượng ánh sáng tốt, dễ dàng trong việc quan sát các đối tượng.
–Điều kiện thời tiết chủ yếu là nắng và trời râm, khi train với tập ảnh này sẽ luyện cho mô hình khả năng nhận diện biển báo, đèn tín hiệu ở những hoàn cảnh khắc nghiệt như ngược hướng nắng, trời sương mù, nhưng cũng có nhược điểm là mô hình chỉ hoạt động tốt ở hai điều kiện trên, điều này là chưa đủ vì quá trình tham gia giao thông, đặc biệt ở Việt Nam, đất nước nằm trong vùng khí hậu nhiệt đới và á nhiệt đới có gió mùa, các điều kiện thời tiết hết sức đa dạng, thì mô hình trên cần phải chạy được ở nhiều loại điều kiện thời tiết hơn nữa.
–Phân phối của tập huấn luyện khác so với thực tế, đó là ở tập huấn luyện, ảnh chứa biển báo và ảnh chứa đèn tín hiệu chiếm tỉ lệ 70:30, tuy nhiên khi sử dụng vào thực tế, lượng ảnh chứa đèn tín hiệu lại khá lớn và chiếm tỉ lệ 50:50 Và ngoài ra vẫn tồn tại một số nguyên nhân phụ khác dẫn tới thuật toán hoạt động không được như kì vọng. Tuy nhiên, dựa vào các nguyên nhân chính mà đã nêu ở trên, em đã tìm hiểu và áp dụng một số phương án để khắc phục các vấn đề, đồng thời cải thiện khả năng chính xác của mô hình qua việc tiền xử lý dữ liệu đầu vào. Phần sau đây em sẽ trình bày chi tiếp về các phương án đã sử dụng cho việc tiền xử lý bộ dữ liệu của mình.
4.1.1 Thay đổi độ tương phản của ảnh Trong những trường hợp dữ liệu là một hình ảnh chụp trong điều kiện thời tiết đẹp, ánh sáng tốt, em đã dùng phương pháp thay đổi độ tương phản của ảnh để làm 27giàu thêm bộ dữ liệu của mình như sau:
Tăng độ tương phản để tạo ra một môi trường với lượng ánh sáng lớn, để áp dụng vào trong các trường hợp khi tham gia giao thông, ánh nắng mặt trời quá mạnh gây khó khăn trong việc nhận diện, đặc biệt là biển báo hay đèn tín hiệu có màu trắng, vàng.
Giảm độ tương phản: tương tự như cách trên, từ ảnh gốc ta sẽ giảm độ tương phản để tạo thêm một ảnh mới. Khi luyện tập với những ảnh này, thuật toán sẽ tăng khả năng nhận diện vật thể ở những điều kiện ánh sáng kém như buổi chiều tối hay buổi đêm.
Ví dụ, từ một ảnh gốc ban đầu trong bộ dữ liệu ban đầu, ản được chụp lúc ban ngày, thời điểm ánh sáng tốt, biển báo và đèn tín hiệu trong ảnh rất rõ ràng:
Hình 4.4: Một ảnh trong bộ dữ liệu được chụp dưới điều kiện ánh sáng tốt Ta sẽ sử dụng hàm adjust_image_gamma để xử lý vấn đề trên, với tham số truyền vào là giá trị gamma để điều chỉnh độ tương phản def adjust_image_gamma ( image , gamma = 1 . 0 ) :
image = np . power ( image , gamma ) max_val = np . max ( image . r a v e l ( ) ) image = image / max_val *255 image = image . a s t y p e ( np . u i n t 8 ) r e t u r n image Ví dụ khi cần tăng độ sáng để giả lập điều kiện ánh nắng từ mặt trời gây chói, ta chỉnh giá trị gamma thấp(ở ví dụ này giá trị gamma = 0.5), ngược lại, để giảm độ sáng xuống giả lập môi trường trời chiều tồi, sử dụng một giá trị gamma lớn(ví dụ bên dưới gamma = 6), ta thu được kết quả như 2 ảnh phía dưới:
28Hình 4.5: Bức ảnh sau khi tăng độ tương phản Hình 4.6: Bức ảnh sau khi giảm độ tương phản Thay đổi các giá trị gamma, ta thu được một tập ảnh với các điều kiện sáng khác nhau từ một ảnh gốc ban đầu:
Hình 4.7: Tập ảnh với các điều kiện sáng khác nhau 4.1.2 Làm mờ ảnh Phép làm mờ ảnh đem lại một số lợi ích như:
Giảm nhiễu trong ảnh Làm trơn ảnh (smooth). Việc làm trơn ảnh sẽ giảm sắc nét của cạnh, thay vào đó, vùng trơn sẽ lan ra Cụ thể trong bài toán nhận diện biển báo và đèn tín hiệu giao thông, từ bức ảnh ở tập huấn luyện ban đầu, ta có thể sử dụng phương pháp làm mờ để tạo ra một bức ảnh mới. Việc này giúp model sau này sẽ nhận ra được các đối tượng cần thiết kể cả trong môi trường khó quan sát như trời mưa hay có sương mù.
29Ví dụ từ ảnh gốc ban đầu, ta sử dụng hàm blur() của thư viện OpenCV, hàm này làm mờ ảnh bằng cách thiết lập giá trị trên bộ lọc bằng 1/(W*H), tức là nếu Width và Height của bộ lọc là 5, thì giá trị trên cửa sổ convolve là 1/25.
Hình 4.8: Ảnh gốc khi chưa chạy qua bộ lọc làm mờ Hình 4.9: Ảnh gốc sau khi chạy qua bộ lọc làm mờ Tương tự như cách xử lý ở phần thay đổi độ tương phản, ta sẽ thực hiện với một tập (W, H)chạy từ 5-9 để tạo ra một bộ ảnh với các độ mờ khác nhau từ một ảnh gốc ban đầu:
Hình 4.10: Bộ ảnh với các độ blur khác nhau tạo ra từ ảnh gốc 4.1.3 Loại bỏ phần dữ liệu không đủ điều kiện Sau khi thực hiện một số công việc để bổ sung các điều kiện khác nhau vào bộ dữ liệu, ta thu được một bộ dữ liệu mới với kích thước lớp gấp chục lần bộ dữ liệu ban đầu. Tuy nhiên trong đó có vô số ảnh không đảm bảo điều kiện như sau khi chạy qua bước điều chỉnh độ tương phản, sẽ có những ảnh quá sang hoặc quá tối, 30hay khi chạy qua bộ làm mờ, có những ảnh bị làm mờ đi nhiều quá, hay cũng có những kết quả 2 bức ảnh không có sự khác biệt quá lớn sau khi chạy qua những bộ lọc trên. Những trường hợp này sẽ gây chậm quá trình huấn luyện và tác dụng làm tăng độ chính xác của thuật toán gần như bằng 0, ta sẽ phải thực hiện xoá bỏ đi những dữ liệu dư thừa này. Sau khi đã xoá bỏ được những hình ảnh không đủ điều kiện ở trên, ta sẽ thu được bộ ảnh với các điều kiện ánh sáng và độ mờ khác nhau, điều này giúp cho thuật toán sau này khả thi trong các điều kiện sáng, tối hay thời tiết xấu như mưa, sương mù,....
4.1.4 Bổ sung bộ dữ liệu về các phương tiện giao thông để phục vụ cho việc hậu xử lý dữ liệu Việc nhận diện đèn tín hiệu ở điều kiện ban đêm là hết sức quan trọng và cần thiết, tuy nhiên nó cũng đem lại rất nhiều khó khăn vì vào ban đêm, môi trường bên ngoài có rất nhiều nguồn sáng khác nhau. Bên cạnh những đối tượng là đèn giao thông mà mô hình của chúng ta cần nhận diện, còn có những nguồn sáng khác như đèn đường, đèn từ cửa hàng, nhà dân, biển quảng cáo,... và nhiều nhất là đèn từ các phuong tiện giao thông, phổ biến nhất là xe tải, ô tô, xe máy,... Những nguồn sáng này gần như không có sự khác biệt với các đèn tín hiệu giao thông, vì vậy nếu không có cách xử lý với những nguồn sáng từ các phương tiện này thì tỉ lệ nhận diện các đèn tín hiệu sẽ rất lớn.
Hình 4.11: Dễ dàng nhâm lẫn đèn từ các phương tiện giao thông thành đèn tín hiệu giao thông Để giải quyết vấn đề trên , em đã tận dụng khả năng nhận diện nhiều đối tượng một lúc của model YOLOv5 bằng cách bổ sung một bộ dữ liệu về các phương tiện giao thông, cụ thể là 3 loại phương tiện phổ biến : xe tải, ô tô, xe máy. Việc nhận diện những phương tiện này sẽ góp phần cho việc xử lý ảnh đầu ra mà em sẽ nên ở phần sau.
31Hình 4.12: Bộ dữ liệu bổ sung cho việc nhận diện phuong tiện giao thông, phục vụ hậu xử lý sau này 4.1.5 Cấu trúc bộ dữ liệu phục vụ cho quá trình huấn luyện Trong folder train_data sẽ có 2 cấu trúc thư mục là images và labels, thư mục images để chứa các hình ảnh biển báo giao thông và thư mục labels dùng để xác định được các nhãn tên gắn trên hình ảnh để hỗ trợ chuẩn đoán hay xác định chính xác dấu hiệu Hình 4.13: Cấu trúc thư mục train_data Chúng ta sử dụng tool LabelImg để đánh nhãn vật thể trong hình. Đây là một công cụ hỗ trợ mạnh mẽ trong việc đánh nhãn vật thể để train các model detection như YOLO.
32Hình 4.14: Gán nhãn hình ảnh bằng LabelImg File gán nhãn .txt có format như sau:
Mỗi hàng sẽ là một đối tượng.
Mỗi hàng sẽ có format: class x_center y_center width height.
Toạ độ của các box sẽ được normalized (từ 0-1) theo format xywh Class sẽ bắt đầu từ 0.
4.2 Thiết lập môi trường huấn luyện nhận dạng biển báo và đèn tín hiệu giao thông Yêu cầu Pytorch version 1.5 trở lên, Python version 3.7 và CUDA Để bắt đầu với YOLOv5, trước tiên sao chép kho lưu trữ YOLOv5 và cài đặt các tính năng phụ thuộc.
Hình 4.15: Clone model và cài đặt các requirements Tạo file /yolov5/data/custom_data.yaml để chỉ định vị trí của thư mục hình ảnh YOLOv5, thư mục nhãn YOLOv5 và thông tin về các lớp custom.
33Hình 4.16: Cấu hình lại file yaml 4.3 Traning Để bắt đầu huấn luyện, ta chạy the training command theo tùy chọn sau:
img: xác định kích thước hình ảnh đầu vào batch: số ảnh để load vào (16-32) một lần epochs: số lần học data: đặt đường dẫn đến tệp yaml cfg: chỉ định cấu hình mô hình weights: chỉ định một đường dẫn tùy chỉnh đến weights.
name: tên kết quả nosave: chỉ lưu điểm kiểm tra cuối cùng cache: hình ảnh trong bộ nhớ cache để train nhanh hơn 4.4 Xử lý các trường hợp nhận diện nhầm đèn tín hiệu với đèn của các phương tiện giao thông Như đã đề cập ở phần trước, việc di chuyển trong điều kiện ban đêm, khi mà ngoài đèn tín hiệu còn rất nhiều đèn sáng đến từ nhiều nguồn khác nhau, phổ biến nhất là đèn từ các phương tiện giao thông như xe tải, ô tô, xe máy. Và model sau khi huấn luyện của chúng ta đang bị nhầm với những nguồn đèn này. Vì vậy để giải quyết vấn đề trên, trong bộ dataset ngoài dữ liệu về đèn tín hiệu và biển báo giao thông, em còn bổ sung thêm dữ liệu về các phương tiện giao thông để phục vụ cho phần hậu xử lý dữ liệu.
Dễ dàng nhận thấy trong trường hợp có ánh đèn phát ra từ phương tiện giao thông, model sẽ trả về kết quả là bounding box của hai đối tượng: phương tiện và đèn tương ứng. Và vùng nhận diện của đèn thường sẽ nằm 75-100% diện tích trong 34vùng nhận diện của phương tiện:
Hình 4.17: Model nhận diện ô tô và đèn Ta sẽ xây dựng một hàm để lọc các trường hợp này và loại bỏ khả năng đây là đèn tín hiệu giao thông.
Lấy toạ đọ của vật thể dựa trên file best.pt đã huấn luyện model = t o r c h . hub . l o a d ( ’ u l t r a l y t i c s / yolov5 ’ , ’ custom ’ , p a t h = ’ . / b e s t . pt ’ ) d e t e c t i o n s = model ( frame ) r e s u l t s = numpy . a r r a y ( d e t e c t i o n s . pandas ( ) . xyxy [ 0 ] . t o _ d i c t ( o r i e n t =" r e c o r d s " ) ) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− p T r a n s p o r t = Polygon ( [ ( r e s u l t T r a n s p o r t . xmin , r e s u l t T r a n s p o r t . xmax ) , ( r e s u l t T r a n s p o r t . xmax , r e s u l t T r a n s p o r t . ymin ) , ( r e s u l t T r a n s p o r t . xmax , r e s u l t T r a n s p o r t . ymax ) , ( r e s u l t T r a n s p o r t . xmin , r e s u l t T r a n s p o r t . ymax ) , ] ) pL ight = Polygon ( [ ( r e s u l t L i g h t . xmin , r e s u l t L i g h t . xmax ) , 35( r e s u l t L i g h t . xmax , r e s u l t L i g h t . ymin ) , ( r e s u l t L i g h t . xmax , r e s u l t L i g h t . ymax ) , ( r e s u l t L i g h t . xmin , r e s u l t L i g h t . ymax ) , ] ) Gọi đến hàm checkTrafficLight, kiểm tra xem đối tượng đèn là đèn tín hiệu hay đèn phương tiện giao thông i s T r a f f i c L i g h t = c h e c k T r a f f i c L i g h t ( p T r a n s p o r t , pLi ght ) i f i s T r a f f i c L i g h t :
#Xu l y : thong bao cho nguoi dung co den t i n h i e u t r e n duong e l s e :
# Loai bo t r u o n g hop p Lig ht l a den t i n h i e u def c h e c k T r a f f i c L i g h t ( p T r a n s p o r t , pLi ght ) :
i n t e r s e c t i o n = p T r a n s p o r t . i n t e r s e c t i o n ( pLi ght ) ; i f i n t e r s e c t i o n . a r e a == 0 . 0 :
r e t u r n True i f ( i n t e r s e c t i o n . a r e a ) / ( pL igh t . a r e a ) >= 0 . 7 5 :
r e t u r n True e l s e :
r e t u r n F a l s e 4.5 Kết quả chương trình Sau quá trình train, trọng số (weights) của model Yolov5 sẽ được lưu trong thư mục run/train/exp/weights, đó là weights của của epoch tốt nhất và best.pt và epoch cuối cùng last.pt.
Kết quả của việc huấn luyện được mô tả dưới đây:
Confusion matrix (ma trận nhầm lẫn), ma trận này sẽ cho ta biết được tỉ lệ dự đoán chính xác hoặc tỉ lệ nhầm lẫn giữa các đối tượng với nhau. Ví dụ theo sơ đồ trên ta thấy biển cấm rẽ có tỉ lệ nhận diện chính xác là 0.56 hay 56%, tuy nhiên tỉ lệ nhận diện nhầm biển này với biển giới hạn tốc độ cũng đang cao là 30%, haybieern giới hạn tốc độ cũng đang gây nhiễu khi model nhận diện là cấm rẽ tỉ lệ nhầm lẫn 14%... Dựa vào kết quả trong ma trận này ta đưa ra được đánh giá tổng quát mô hình nhận diện các vật thể cần thiết ở tỉ lệ khá tốt.
36Hình 4.18: Confusion_matrix Sơ đồ sự phụ thuộc giữa Precision-Confidence và Recall-Confidence:
Hình 4.19: Sơ đồ P_curve 37Hình 4.20: Sơ đồ R_curve Dựa trên biểu đồ kết quả trên, ta đưa ra nhận xét kết quả model dự đoán khá tốt khi các giá trị box_loss, obj_loss, cls_loss đều giảm giần qua các lần train, còn các giá trị mAP tăng dần qua các lần train.
Hình 4.21: Kết quả huấn luyện Thực hiện detect ta thu được một số kết quả sau:
38Hình 4.22: Phát hiện biển báo Cấm dừng, đỗ Hình 4.23: Phát hiện đèn xanh, biển cấm rẽ, biển cấm ngược chiều Hình 4.24: Phát hiện đèn đỏ và biển báo Cấm đi ngược chiều 39Hình 4.25: Phát hiện biển báo Cấm dừng, đỗ và cấm đi ngược chiều trong điều kiện ban đêm Hình 4.26: Phát hiện đèn tín hiệu trong điều kiện ban đêm Hình 4.27: Phát hiện đèn tín hiệu trong điều kiện nắng gắt 405.1 Kết luận Sau một thời gian tìm hiểu đề tài, em đã phần nào hiểu hơn về những nội dung cơ bản của bài toán Nhận diện biển báo và đèn tín hiệu giao thông. Tìm hiểu được thêm nhiều khái niệm, nội dung cơ bản liên quan đến đề tài như những thuật ngữ cơ bản trong nghành trí tuệ nhân tạo, học máy, nhận dạng vật thể, những khái niệm về phương pháp học sâu sử dụng mạng neural để nhận diện vật thể... Cài đặt và áp dụng chạy thử mô hình đối với bài toán đặt ra. Sau quá trình xử lý và điều chỉnh dữ liệu, môi trường huấn luyện, thuật toán cũng đã cho ra những kết quả khả quan, khả thi trong việc sử dụng vào thực tế. Tuy nhiên em vẫn gặp phải nhiều khó khăn và hạn chế trong quá trình thực hiện.
Khó khắn của bản thân là chưa có nhiều kiến thức, kinh nghiệm thực tế để xây dựng một mô hình tốt hơn có thể giải quyết bài toán nêu trên. Do đây cũng là lần đầu tiên em tham gia dự án về trí tuệ nhân tạo, cụ thể là Thị giác máy tính, vẫn còn nhiều vấn đề em chưa nắm rõ và hiểu hết được. Đồng thời trong quá trình xây dựng và huấn luyện model, các thông số kỹ thuật vẫn chưa được như mong muốn. Vì vậy vẫn rất cần cải tiến hơn trong giai đoạn sau này..
5.2 Hướng phát triển trong tương lai Dựa vào sự phát triển công nghệ mạnh mẽ như hiện nay thì tương lai có thể sử dụng các phiên bản YOLO mới nhất và nhiều mạng khác như Single Shot Detector, RentiaNet, CenterNet,. . . để có thể huấn luyện và nhận dạng được nhiều nhóm biển báo giao thông một cách chính xác và nhanh gọn hơn nhằm:
Cải tiến chất lượng bộ huấn luyện phát hiện ảnh biển báo.
Mở rộng cơ sở dữ liệu biển báo giao thông.
Cải tiến phương pháp giải quyết trường hợp các biển báo bị hư hỏng hoặc bị chồng lấp.
Nâng cấp và hoàn thiện khả năng của hệ thống trở thành một hệ thống nhận dạng và đưa ra cảnh báo tức thời cho người tham gia giao thông trong một chương trình hoàn chỉnh.
41 Afshine Amidi, Shervine Amidi, Convolutional neural networks cheatsheet .
url:
cheatsheet-convolutional-neural-networks (urlseen 22/07/2022).
Rohith Gandhi, R-cnn, fast r-cnn, faster r-cnn, yolo — object detection algorithms .
url:https : / / towardsdatascience . com / r- cnn - fast - rcnn-faster-r-cnn-yolo-object-detection-algorithms 36d53571365e (urlseen 25/07/2022).
Jedrzej ´Swie ˙zewski, Ph.D., Yolo algorithm and yolo object detection .url:
(urlseen 22/07/2022).
42