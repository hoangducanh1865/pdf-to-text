Artificial Intelligence (AI) is evolving at an extraordinary pace, inspiring inno vative methods that blend disparate computational fields to tackle some of the most demanding challenges. In this rapidly shifting landscape, two particular paradigms stand out for their strengths yet have traditionally advanced on separate tracks: EC and LLMs. EC, inspired by natural evolution, explores populations of candidatesolutions to discover high-quality outcomes, whereas LLMs are adept at generat ing coherent, context-aware outputs ranging from textual prose to executable code.
As AI applications become more ambitious, a growing area of research, known as LLM-EPS, seeks to harness the best of both worlds: leveraging the adaptive search prowess of EC and the creative and generative capabilities of LLMs. This emerging fusion offers a novel route for solving challenges in AHD.
Initial research indicates that aligning the iterative adjustments of EC with theadaptable generation abilities of LLMs can lead to significant advancements, especially in the creation of heuristic programs, code fragments, or even written so lutions. Nevertheless, an essential question persists: How can diversity be ensuredthroughout the evolutionary process? This is particularly important when candi date solutions are no longer merely simple numeric vectors but are instead diverse forms of code or text. Preserving diversity is paramount to avoid converging tooquickly on suboptimal solutions and to maintain an expansive search of the so lution landscape. The subsequent sections provide an overview of EC principles, discuss the capabilities and constraints of modern LLMs, and survey recent strides in LLM-EPS research, with special attention to how future investigations might harness diversity to unlock even more powerful solutions.
1.1 Related works Although the convergence of EC and LLMs for optimization and AI is still a relatively new domain, it builds upon two longstanding bodies of research thathave more often evolved in isolation. EC traditionally tackles numerical or combinatorial challenges, while LLMs excel at text-oriented tasks like language translation, content generation, and summarization. Current work in LLM-EPS illustrates how these fields can be merged: LLMs become generators of candidate solutions whether code snippets, pseudo-code, or textual explanations, and evolution ary frameworks guide these outputs toward continuous improvement.
Recent studies show this collaboration. In code generation, studies [7], [16], [17] showcase evolutionary strategies that refine LLM suggested programs for enhanced quality and resilience. In text generation [18], [19] illustrates how evolutionary refinement can produce more precise and diverse linguistic outputs. Together, these works point to tangible gains, including improved error resolution, larger solution spaces, and quicker convergence.
Nevertheless, most existing research [13]‚Äì[15] focuses on performance indicators without explicitly examining how population diversity can be steered or main tained when solutions take the form of human-readable code or text. This missing piece is critical for keeping evolutionary searches from prematurely collapsing on local optima and for fostering creative, wide-ranging solution sets. Future efforts, therefore, might delve deeper into incorporating diversity metrics to ensure that LLM-driven evolutionary processes not only excel in performance but also yield robust and flexible results across numerous domains.
1.2 Evolutionary computationEC [20] is one computational intelligence model used to mimic the biological evolution phenomenon. Currently, EC includes four algorithms: Genetic Al gorithm (GA), Evolutionary Programming (EP), Evolution Strategies (ES), and Genetic Programming (GP). GA was proposed by the American scholar Holland in the 1950s in a study of self-adapting control. To study the finite-state machine of AI, the American scholar Fogel proposed EP in the 1960s. At nearly the same time,the German scholars Rechenberg and Schwefel proposed ES to solve numerical op timization. In the 1990s, based on the GA, the American scholar Koza proposed GP to study the automatic design of computer programs.
Although the four algorithms were proposed by different scholars for different purposes, their computing processes are similar and can be described as follows.
1. One group of initial feasible solutions are created; 2. The properties of the initial solutions are evaluated; 3. The initial solutions are selected according to their evaluation results; 4. The selected solutions are conducted by the evolutionary operations and the next generation of feasible solutions can be obtained;5. If the feasible solutions obtained during the above step can meet the requirements, then the computation will stop. Otherwise, the feasible solutions obtained during the above step are taken as the initial solutions, and the compu tation process returns to step 2.
Generally, as one global optimization method, EC has the following characteris tics: (i) The search process begins from one group and not from one point; (ii) only the objective function is used in the search process; and (iii) the random method is used in the search process. Therefore, this method has the following advantages: (i) Highly versatile and can be used for different problems; (ii) it can solve problems that are highly nonlinear and nonconvex; and (iii) the model‚Äôs plasticity is very high and can be deserialized very easily.
The three evolutionary computation algorithms related to the research on thisLLM-EPS include GA, EP, and GP. In the next section of the chapter, these algo rithms are briefly described.
1.2.1 Genetic algorithm Figure 1.1: Flow chart of GA.
As the most widely used EC method, GA has a solid biologic foundation. Its basic principles are from Darwin‚Äôs evolution theory and Mendel‚Äôs genetic theory [21]. The basic GA flow chart is shown in Figure 1.1. The main operations of GA are as follows.
1. Individual encoding. According to Mendel‚Äôs genetic theory, the individual must be represented by its genotype. Therefore, the binary encoding method is generally applied, which is one string of numbers 0 and 1. However, for a complicated engineering problem, the real encoding method is always used, which is one string of a real number.
2. Crossover operation. This operation is completed to mimic the genetic re combination during biological mating. Generally, random pairing is applied.
For different encoding methods, the crossover operation is different. For bi nary encoding, the point crossover is utilized. For real encoding, the discrete crossover and arithmetic crossover are always used. Moreover, this operation is conducted with a large probability.
3. Mutation operation. This operation is completed to mimic the gene mutation during the genetic process. Generally, for binary encoding, the simple point mutation is utilized. For real encoding, the uniform mutation and non-uniform mutation are always used. Moreover, this operation is conducted with a little probability.
4. Selection operation. This operation is completed to mimic the environmentselection of Darwin‚Äôs evolution theory. Therefore, it is also called the reproduction operation. Generally, roulette wheel selection is widely used. However, stochastic tournament selection is a better operation for complicated en gineering problems.
5. Termination criterion. Generally, the termination criterion specifies that the difference between the maximum fitness value and average fitness value ofone group is less than one error œµ. To avoid infinite iteration, a maximum num ber of evolutionary generations is also specified. Moreover, there are someparameters to be determined: the number of individuals, crossover probabil ity, mutation probability, œµ and maximum number of evolutionary generations.
Generally, these parameters are determined based on experience and a test.
1.2.2 Evolutionary programming The main operations of EP are as follow [22], [23].
1. Mutation operation. This operation is the sole optimization operation; this is the specialty of the EP. Generally, Gauss random mutation is utilized.
2. Testing feasibility of the individual. The fundamental nature of mutation in volves a type of random alteration to the original individual, which means it cannot ensure that the newly mutated individual remains within the searchspace; in other words, a non-feasible individual could be generated. The exis tence of a non-feasible individual can not only make the result incorrect but also make the efficiency low. To overcome this problem, a simple and easy method is proposed [23]. If the new mutated individual is non-feasible, it will be replaced by a randomly created feasible individual. However, this technique may have a very low efficiency for certain problems.
3. Selection operation. The selection operation is a stochastic tournament model, where individuals are probabilistically chosen based on their fitness, ensuring a balance between exploration and exploitation.
4. Termination condition. This is the same as that of the GA. Moreover, thereare some parameters to be determined: the number of individuals, œµ and max imum number of evolutionary generations. Thus, the number of parameters for EP is less than that for the GA. Generally, these parameters can also be determined based on experience and a test.
1.2.3 Genetic programming Because GP is proposed based on the basic GA principles, the procedures of two algorithms are nearly the same [24]. The main operations of GP are as follows.
1. Individual encoding. The tree encoding method is applied. In other words, the layering tree structure expression is applied, which is shown in top of Figure 1.3.
2. Crossover operation. Generally, random pairing and point crossover are uti lized. This operation is also conducted with a large probability.
3. Mutation operation. Generally, simple point mutation is utilized. This oper ation is conducted with a little probability.
4. Selection operation. Generally, roulette wheel selection is used.
5. Termination criterion. This is the same as that of GA. Moreover, the param eters are the same as those of GA.
1.3 Large language models LLMs are sophisticated AI systems that specialize in understanding, generating, and predicting human-like text. By analyzing extensive datasets, these models havemade remarkable strides in various natural language processing tasks. Their capabilities include text generation, translation, and summarization, enhancing commu nication and information retrieval across different applications.
The evolution of language models has progressed from statistical methods to sophisticated neural network-based approaches:
‚Ä¢ Statistical language models: Early models, such as n-grams, estimated the probability of a word based on its preceding words but struggled with data sparsity and limited context understanding.
‚Ä¢ Neural network models: The introduction of neural networks allowed for continuous word representations, alleviating some limitations of statisticallanguage models. Recurrent neural networks and long short-term memory net works were employed to capture sequential data dependencies.
‚Ä¢ Transformer architecture: Introduced in [25], transformers utilize self-attentionmechanisms to process input data in parallel, enabling the capture of longrange dependencies more effectively. This architecture underpins many mod ern LLMs.
LLMs are built upon several key concepts. Fristly, LLMs assign probabilities to sequences of words, modeling the likelihood of a word following a given context.
This is formalized as:
P(w1, w2, . . . , wn) = n Y i=1 (1.1) given its preceding words.
Secondly, LLMs employ deep neural networks with multiple layers and param eters to learn complex language patterns. The training process involves adjusting these parameters to minimize a loss function, typically the cross-entropy loss:
L = ‚àí N X i=1 (1.2) where N is the number of words in the training corpus.
Finally the heart of modern LLMs lies the Transformer architecture (Figure 1.2).
Transformers use self-attention mechanisms to weigh the importance of differentwords in a sequence, enabling the model to capture contextual relationships effec tively. The self-attention mechanism is computed as:
Attention(Q, K, V ) = softmax  QKT  V (1.3) where Q (queries), K (keys), and V (values) are matrices derived from the input embeddings, and dk is the dimensionality of the keys.
Training LLMs involves several key steps. First, data collection is essential, asit requires aggregating extensive text data from diverse sources to capture a wide range of language patterns. Once the data is collected, model training begins, uti lizing high-performance computing resources to optimize the model‚Äôs parameters through techniques such as gradient descent. Additionally, scaling laws have been empirically observed, which suggest that increasing the model size, training data, and computational resources leads to improved performance. One notable scaling law is represented by the equation (1.4) where C is the training cost in FLOPs, N is the number of model parameters, D is the size of the training dataset in tokens, and C0 is a constant.
Figure 1.2: Architecture of large neural models [25], [26].
Despite their capabilities, LLMs face with several limitations. LLMs may gen erate factually incorrect or contextually misleading outputs colloquially known as‚Äúhallucinations.‚Äù In addition, their large, black-box structures can complicate in terpretability, making it challenging to understand precisely why a particular tokenor code snippet is produced. Moreover, controlled generation, where specific constraints or style guides must be applied, can be non-trivial to implement. Regard less, their unprecedented ability to generate complex textual or code-based artifacts has spurred interest in integrating LLMs into evolutionary workflows, particularly for tasks that benefit from a human-like creative spark.
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ0 ¬∑¬∑¬∑ ¬∑¬∑¬∑ LLM-based EPS: better heuristics are created via prompting LLMs over program codes.
evolve ¬∑¬∑¬∑ ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ0 exchange sub-parts ¬∑¬∑¬∑ ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ1 selection Genetic Programming: better heuristics are created through genetic operations over trees.
¬∑¬∑¬∑ ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõùëõ ¬∑¬∑¬∑ selection Generate a heuristic inspired by the given examples Prompting Generated heuristic:
LLM ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõùëò ¬∑¬∑¬∑ ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ1 ¬∑¬∑¬∑ ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ%&' ¬∑¬∑¬∑ Function set add  sub for  sum ‚ãØ‚ãØ Terminal set bins items true false ‚ãØ‚ãØ specified by human experts def initial_heuristic(item: float, bins: list) -> list:
```Define priority with which we assign an item to each bin.
:param item: Size of item to be added to the bin.
:param bins: List of capacities for each bin.
:return: a list showing priority score of each bin.
``` return [0] * len(bins) Figure 1.3: An illustration of the LLM-based EPS paradigm, with respect to the GP-based paradigm (top section), for AHD [27].
1.4 LLM-based evolutionary program search LLM-EPS combines the adaptive search capabilities of evolutionary algorithms with the generative power of LLMs, unlocking new possibilities for AHD. Unliketraditional optimization methods that produce numeric solutions, LLM-EPS gener ates interpretable programs or code snippets, allowing for seamless interaction and validation by human expert an attractive feature for real-world applications. Figure 1.3 illustrates the fundamental differences between GP and LLM-EPS.
1.4.1 FunSearchFunSearch, short for "search in the function space," represents a groundbreak ing approach in leveraging LLMs for program synthesis and optimization. Unliketraditional methods, which often face limitations due to hallucinations or verifi cation challenges. FunSearch innovatively combines an LLM with a systematicevaluator. This evaluator rigorously scores candidate programs, ensuring correct ness and quality, and plays a pivotal role in evolving low-performing solutions into high-quality, optimized programs.
At the core of FunSearch‚Äôs architecture, as shown in Figure 1.4, is its evolu tionary methodology, which starts with a user-defined "skeleton" program. This skeleton encapsulates known functional structures and isolates the critical logic for optimization, thereby reducing the search space and improving accuracy. Thesystem employs an island-based model to maintain a diverse pool of candidate programs, as shown in Figure 1.5. By avoiding local optima and encouraging diversity Figure 1.4: The FunSearch process [13]. The LLM is shown a selection of the best pro grams it has generated so far (retrieved from the programs database), and asked to generate an even better one. The programs proposed by the LLM are automatically executed, and evaluated. The best programs are added to the database, for selection in subsequent cycles.
The user can at any point retrieve the highest-scoring programs discovered so far.
Figure 1.5: Program clusters within islands of FunSearch [13].
through genetic-like operations, FunSearch achieves robust exploration across a wide range of program variations.
The distributed architecture of FunSearch enhances scalability and efficiency.
The system comprises three main components: a programs database, samplers, and evaluators. The programs database stores correct and promising programs, while samplers use LLMs to generate new variations based on prompts constructed from high-scoring programs. Evaluators assess these programs by executing them against a predefined "evaluate" function, which measures the quality of outputs on specific inputs. These components operate asynchronously, leveraging parallelism to handle computationally intensive tasks efficiently.
FunSearch‚Äôs iterative process integrates several innovative techniques. Best-shot prompting ensures that high-quality programs guide the evolution process, whileclustering within islands helps preserve program diversity. The inclusion of Boltz- mann selection mechanisms and fitness-based sampling further refines the evolutionary trajectory, favoring both performance and interpretability. The system‚Äôs dis tributed nature supports scalability, enabling it to tackle large, complex problems across a variety of domains, from mathematical discovery to algorithm design.
This architecture not only delivers impressive results but also highlights FunSearch‚Äôs adaptability. By systematically blending the creativity of LLMs with rig orous evaluation and evolutionary improvements, FunSearch sets a new benchmarkfor program synthesis, pushing the boundaries of what LLMs can achieve in struc tured problem-solving.
1.4.2 Evolution of heuristics Algorithm Parent Algorithm Offspring Algorithm Algorithm Algorithm Parent Algorithm Parent Algorithm Offspring Algorithm Algorithm Example Algorithm Crossover Example Algorithm Mutation Parent Algorithm 1 ‚Ä¢ Description: Select the next unvisited node that is nearest to the current node ‚Ä¢ Code:
Parent Algorithm 2 ‚Ä¢ Description: Select the next unvisited node that is farthest to the destination node ‚Ä¢ Code:
Offspring Algorithm ‚Ä¶ Algorithm Mutation Prompt Engineering Algorithm Crossover Prompt Engineering def name (input1, ‚Ä¶, inputI) parent code 1 return output def name (input1, ‚Ä¶, inputI) parent code 2 return output ‚Ä¢ Description: Select the next unvisited node that has the smallest distance to the current node, subtracting the distance to the destination node.
‚Ä¢ Code:
def name (input1, ‚Ä¶, inputI) offspring code return output Offspring Algorithm ‚Ä¢ Description: Select the next unvisited node that has the smallest distance to the current node, subtracting the distance to the destination node.
‚Ä¢ Code:
def name (input1, ‚Ä¶, inputI) parent code return output Parent Algorithm ‚Ä¢ Description: Select the next unvisited node that with the smallest ratio of the distance to the current node divided by the distance to the destination node ‚Ä¢ Code:
def name (input1, ‚Ä¶, inputI) offspring code return output Offspring Algorithm Crossover using LLM Mutation using LLM Selection Population Offspring Algorithm Evaluation On Instances Population Management Figure 1.6: An illustration of the AEL framework [28], which serves as a foundational prior for EoH.
Prompt Strategies:
1) Exploration:
E1        E2 2) Modification:
M1       M2       M3 Thought Code Augment Heuristics Figure 1.7: EoH evolves both thoughts and codes using LLMs [14].
Another noteworthy approach is Evolution of Heuristics (EoH), aimed explicitly at AHD while minimizing manual labor. EoH represents heuristics both as natural language ‚Äúthoughts‚Äù and as executable code, mirroring the way human experts conceptualize and then implement strategies. By employing a population-based algorithm, EoH evolves these heuristics over successive generations with selection, crossover, and mutation operations guided by LLMs.
EoH employs a population-based evolutionary model where heuristics evolve over generations. Selection, crossover, and mutation operations enhanced by LLMs generate new heuristics iteratively (Figure 1.6). Five specific prompt strategies guide this evolution (Figure 1.7). Divide to, Exploration: includes generating novelheuristics (E1) or exploring variations based on common ideas (E2); and Modi fication: focuses on refining heuristics for improved performance (M1), adjusting parameters (M2), or simplifying structures by eliminating redundancies (M3).
This method requires fewer queries to LLMs compared to previous techniques such as FunSearch. Additionally, it eliminates the need for custom-crafted features or additional training. The upshot is a more streamlined method that outperformsmanually created heuristics across diverse optimization benchmarks. As EoH re duces the overhead of domain-specific engineering, it underscores the breadth of potential applications for LLM-EPS.
1.4.3 Reflective evolution </> </> </> ......
Selection ......
Evaluate Relative Performance Reflector LLM ......
Short-term Reflections </> </> ......
Generation Instructions Task Specification Short-term Reflection Generator LLM </> </> ......
Offspring Heuristics Crossover Reflector LLM Long-term Reflection Long-term Reflection </> Elite Long-term Generator LLM </> </> ......
Mutated Heuristics Heuristic Reflection Elitist Mutation </> A population of heuristics A population of heuristics ......
A population of heuristics Long-term Reflection Previous Long-term Long-term Reflection Long-term Reflection ......
Reflection Performance indicator ......
......
</> </> ......
</> ......
Figure 1.8: ReEvo pipeline [15].
In pursuit of state-of-the-art results, Reflective Evolution (ReEvo) integrates LLMs with a GP foundation to tackle NP-hard combinatorial optimization tasks.
ReEvo employs two types of LLMs: a Generator LLM, which produces initial code snippets or heuristics, and a Reflector LLM, which provides both short-term and long-term reflections to guide iterative improvements.
The genetic cycle in ReEvo, as shown in Figure 1.8 consists of the following steps: (i) Population Initialization: Prompts generate initial heuristic candidates.
(ii) Selection: Parent heuristics are chosen based on their performance. (iii) Short term Reflection: Comparative analysis of parent performance informs offspring generation. (iv) Crossover: Generates offspring by combining parent features. (v) Long-term Reflection: Consolidates insights from iterations to improve heuristicgeneration. (vi) Elitist Mutation: Refines the best heuristic further using accumu lated reflections.
By synthesizing immediate feedback (short-term reflection) and broader insights (long-term reflection), ReEvo delivers sample-efficient heuristics, surpassing frameworks like EoH and FunSearch. Its verbal ‚Äúgradient,‚Äù derived from reflec tive insights, leads to a gentler fitness landscape and boosts optimization stability, making it a potent approach for real-world combinatorial problems.
1.5 Diversity in evolutionary computation Diversity is a cornerstone of successful evolutionary algorithms, especially in scenarios with multiple objectives [29]. A population rich in diverse solutionsmaintains broad coverage of the search space, mitigating the dangers of stagna tion in local optima and supporting adaptability to non-static or convoluted fitness landscapes. Various methods clustering, niching, or entropy-based measures have been proposed to safeguard diversity, with Shannon entropy being a popular metric for assessing how ‚Äúspread out‚Äù a set of solutions is [30], [31].
However, embedding these diversity concepts into LLM-EPS raises fresh challenges. Populations are not numeric vectors but heuristic code snippets or descrip tive text, which calls for alternative ways to quantify ‚Äúdistance‚Äù or ‚Äúdifference.‚ÄùWhat strategies can be employed to evaluate the semantic gap between two heuris tic code snippets or two text proposals while effectively capturing their functional differences? These inquiries highlight a pressing need for innovative strategies in diversity management that are compatible with LLM-based searches.
Crucially, diversity acts not only as a buffer against premature convergence, butalso as a catalyst for creative or unconventional strategies, a vital ingredient in ad vanced heuristic design. By developing refined diversity metrics and preserving variability throughout the evolutionary process, researchers can unlock a broaderrange of potential solutions, leading to improved performance and more generaliz able outcomes.
This chapter has charted the emerging partnership between EC and LLMs, show casing how their combined strengths can transform AHD. In LLM-EPS, LLMs contribute a wellspring of fresh heuristic ideas, and evolutionary methods system- atically sharpen and validate these concepts. Yet, to extract maximum value from this synergy, careful attention must be paid to diversity the balancing force that fosters both robust exploration and refined exploitation.
From traditional GA to newer frameworks like FunSearch, EoH, and ReEvo, the literature consistently highlights the importance of extensive exploration toavoid becoming trapped in suboptimal solutions. Diversity is the crucial compo nent that integrates a genuinely adaptive search process, facilitating breakthroughs in problem-solving. In the following chapter, advanced methods for incorporating diversity into LLM-EPS will be examined.
This chapter introduces a method for encoding the LLM-EPS population and proposes two metrics for measuring diversity: SWDI and CDI. Following this, a diversity analysis will be conducted on previous LLM-EPS frameworks, including FunSearch, EoH, and ReEvo.
2.1 Population encoding One particular problem in measuring diversity in LLM-EPS is how to encode the population. While each individual in the traditional evolutionary algorithm is encoded as a vector, in LLM-EPS they are usually presented as a string of code snippets/programs. This poses a challenge in applying previous diversity metricsto the population of LLM-EPS frameworks. To address this challenge, an encoding method is proposed that involves three steps: (i) removing comments and doc strings using abstract-syntax tree, (ii) standardizing code snippets into a common coding style (e.g., PEP81), (iii) converting code snippets to vector representations using a code embedding model.
2.2 Shannon‚ÄìWiener diversity index Inspired by ecological studies, [32] provides a quantitative measure of species diversity within a community. In the context of search algorithms, this index aims to quantify the diversity of the population at any given time step based on clusters of individuals. To compute the SWDI for a specific set of individuals within a community, or archive, it is first necessary to determine the probability distribution of individuals across the clusters. This is represented as:
M (2.1)where Ci is a cluster of individuals and M represents the total number of individu Shannon entropy:
H(X) = ‚àí N X i=1 pi log(pi) (2.2)This index serves as a crucial metric in maintaining the balance between exploration and exploitation within heuristic search spaces. A higher index score suggests a more uniform distribution of individuals across the search space, thus pro 1https://peps.python.org/pep-0008 moting exploration. Conversely, a lower index score indicates concentration aroundspecific regions, which may enhance exploitation but also increase the risk of pre mature convergence.
generated during that time step are added to an archive. The population encoding method described in Section 2.1 is utilized to derive vector representations V = between two embedding vectors vi and vj:
similarity(vi, vj) = vi ¬∑ vj ‚à•vi‚à•‚à•vj‚à• (2.3) To identify clusters in the archive, each embedding vector vi is analyzed. Next, vi will be assigned to a cluster Ci if the similarity between vi and all members of (2.4) be created and vi will be assigned to CN+1. Finally, the SWDI computed score is determined by calculating Equations (2.1) and (2.2) across the identified clusters.
2.3 Cumulative diversity index While SWDI focuses on diversity of different groups of individuals, the CDIplays a crucial role in understanding the spread and distribution of the whole popu lation within the search space [33], [34]. In the context of heuristic search, the CDI measures how well a system‚Äôs energy, or diversity, is distributed from a centralized state to a more dispersed configuration.
Many entropy interpretations have been suggested over the years. The best knownare disorder, mixing, chaos, spreading, freedom and information [35]. The first de scription of entropy was proposed by Boltzmann to describe systems that evolve from ordered to disordered states. Spreading was used by Guggenheim to indicate the diffusion of a energy system from a smaller to a larger volume. Lewis stated that, in a spontaneous expansion gas in an isolated system, information regarding particles locations decreases while, missing information or uncertainty increases.
In graph theory, each edge can be assigned a weight representing, for example, the energy required to traverse that edge. A graph with a complex structure and varying edge weights exhibits higher entropy, indicating a more disordered system.
Conversely, a simpler structure with uniformly distributed weights corresponds to lower entropy.
An Minimum Spanning Tree (MST) of a connected, edge-weighted graph is asubset of the edges that connects all vertices without any cycles and with the min imum possible total edge weight. Constructing an MST can be seen as a process of transitioning from a high-entropy state (the original graph with all its edges andweights) to a lower-entropy state. This transition reflects the idea of energy distribution from a "better located" state to a "more distributed" one, as the MST repre sents the most efficient way to connect all vertices, minimizing the total "energy" or weight.
Consider a connected, undirected graph G = (V, E) with a weight function w :
E ‚ÜíR+. The entropy H of the graph can be associated with the distribution of edge weights. One way to define this entropy is:
H = ‚àí X e‚ààE p(e) log p(e) (2.5) p(e) = w(e) P e‚Ä≤‚ààE w(e‚Ä≤) (2.6) where p(e) is probability-like measure of edge e based on its weight.
The MST, T = (V, ET), is a subgraph where ET ‚äÜE and the total weight Pe‚ààET w(e) is minimized. By selecting the subset of edges that connect all ver tices with the minimal total weight, the MST reduces the system‚Äôs complexity and, consequently, its entropy.
To calculate the CDI, let‚Äôs consider all individuals within an archive, representedby their respective embeddings. By constructing a MST that connects all individu als within the archive A, where each connection between individuals is calculated using Euclidean distance. This MST provides a structure to assess the diversity of the population. Let di represent the distance of an edge within the MST, where pi = di P#A‚àí1 j=1 dj (2.7) The cumulative diversity is then calculated using the Shannon entropy:
H(X) = ‚àí #A‚àí1 X i=1 pi log(pi) (2.8) This method enables the collection of the complete diversity present in the search space, offering valuable information about the range of solutions. Higher CDI values indicate a more distributed and diverse population, which is essential for maintaining a robust search process.
An interesting point in Shannon Diversity Index (SDI) theory is that normalizing the SDI with the natural log of richness is equivalent to the evenness value H‚Ä≤ ln(S) where H‚Ä≤ represents the richness of SDI and S is the total number of possible categories [36]. The significance of evenness is to demonstrate how the proportions of pi are distributed.
Now, consider normalizing with the two current diversity indices. Firstly, in the case of SWID, if there are N clusters and the count of individuals in each cluster from C1 to CN is uniform, then the evenness will consistently equal 1, regardless of the value of N. This is not the preferred outcome since the number of clusters should be considered as a factor of diversity. Likewise, normalizing the CDI willalso overlook the influence of the number of candidate heuristics, which corre spond to the nodes in the MST. This leads to the proposal not to normalize the SWDI and CDI metrics to achieve a [0, 1] bound.
2.4Exploring the correlation between objective score and diversity measure ment metrics To investigate the relationship between the two diversity measurement metrics and the objective score, three experimental runs were performed using ReEvo on three distinct AHD problems, Bin Packing Online (BPO), Traveling SalesmanProblem (TSP) with Guided Local Search (GLS) [37], and Orienteering Problem (OP) with Ant Colony Optimization (ACO) solver [38]. Details of the experi ments can be found in Section 4.1. The diversity evaluation process was conducted with the code embedding model used is CodeT5+2 [39], and similarity threshold objective scores and the two diversity metrics from these runs on BPO, TSP, and OP are presented in Figure 2.1, Figure 2.2, and Figure 2.3, respectively.
From figure 2.1, there are a few observations that can be drawn. First, the two di versity measurement metrics have a noticeable correlation with the objective scores 2https://huggingface.co/Salesforce/codet5p-110m-embedding 100K 200K 300K 400K Total tokens 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 100K 200K 300K 400K Total tokens 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 100K 200K 300K 400K Total tokens 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index Objective score SWDI CDI Figure 2.1: Diversity indices and objective scores of ReEvo framework on BPO problem through different runs.
of the problem. When the objective score is converged into a local optima, the framework either tries to focus on the exploration by increasing the diversity of the population, through the increase of SWDI in the first and second runs or tries to focus on the exploitation of the current population, thus decrease the SWDI in the third run. Focusing on exploration can lead to considerable gains in the objective score, whereas concentrating on exploitation may cause the population to remain stuck in local optima for an extended period. However, if the whole population isnot diverse enough, as can be seen with the low CDI of the second run, the pop ulation might not be able to escape the local optima. These observations about the correlation between the objective score and diversity measurement metrics are similarly reflected in Figures 2.2 and 2.3.
100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Objective score 100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Objective score 100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Objective score 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 Diversity index 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 Diversity index 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 Diversity index Objective score SWDI CDI Figure 2.2: Diversity indices and objective scores of ReEvo framework on TSP through different runs.
2.5 Diversity analysis on previous LLM-EPS framework To analyze the overall diversity of previous LLM-EPS frameworks, experiments were conducted on three distinct LLM-EPS frameworks: FunSearch [13], ReEvo [15], and EoH [14], focusing on three separate AHD problems (BPO, TSP, OP).
The details of each experiment are presented in Section 4.1. Note that, as high- 100K 200K 300K 400K Total tokens 14.5 14.0 13.5 13.0 12.5 Objective score 100K 200K 300K 400K Total tokens 14.5 14.0 13.5 13.0 12.5 Objective score 100K 200K 300K 400K Total tokens 14.5 14.0 13.5 13.0 12.5 Objective score 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Diversity index Objective score SWDI CDI Figure 2.3: Diversity indices and objective scores of ReEvo framework on OP through different runs.
lighted in the previous section, SWDI focuses on understanding the diversity of the population during a single run. As such, it may not help quantify the diversity across multiple experiment runs. Fig. 2.4 presents the experiment results.
100K 200K 300K 400K Total tokens 2.0 2.5 3.0 3.5 4.0 4.5 Objective score BPO 100K 200K 300K 400K Total tokens 2 6 10 Objective score TSP 100K 200K 300K 400K Total tokens 14.5 14.0 13.5 13.0 Objective score OP 2.0 3.0 4.0 5.0 6.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 ReEvo CDI FunSearch Objective score EoH Figure 2.4: CDI and objective scores of previous LLM-EPS on different AHD problems.
In BPO and TSP, EoH obtained the highest CDI but got the worst objective score. This implies that EoH does not focus enough on exploitation to optimize the population better. In contrast, while ReEvo and FunSearch obtain lower CDI than EoH on BPO and TSP, they achieve better objective performance on all three problems. The experiments conducted on the BPO and TSP problems illustrate the inherent trade-off between diversity and objective performance in LLM-EPS frameworks. However, for the OP problem, it is evident that a high CDI is necessary to achieve a better objective score, which aligns with the findings discussed in Section 2.4.
In conclusion, this chapter has introduced a comprehensive approach to mea suring diversity within LLM-EPS frameworks, focusing on SWDI and CDI. Theproposed population encoding method addresses the unique challenge of representing code snippets as vectors, enabling the application of these diversity met rics. Through extensive experiments on various AHD problems, the correlation between diversity metrics and objective scores has been explored, revealing the delicate balance between exploration and exploitation in heuristic search spaces.
The analysis of previous LLM-EPS frameworks, including FunSearch, ReEvo, and EoH, underscores the trade-offs between diversity and performance, highlightingthe importance of maintaining an optimal level of diversity to avoid premature con vergence and enhance solution quality.
This chapter introduces a novel LLM-EPS framework called Harmony Search Evolution (HSEvo). HSEvo aims to enhance the diversity of the population while improving optimization performance and relieving the trade-off between these twoaspects through an individual tuning process based on harmony search. Addition ally, the framework aims to minimize costs associated with LLMs by incorporating an efficient flash reflection component. Figure 3.1 illustrates the pipeline of the HSEvo framework.
3.1 Automatic heuristic design with HSEvoIndividual encoding. In HSEvo, each individual within the evolutionary process is represented as a string of executable code (Figure 3.2a). This concept is a di rect inheritance from earlier LLM-EPS such as EoH and ReEvo. This code snippet, generated by a LLMs, embodies a specific heuristic function tailored to the target optimization problem. This encoding method is deliberately flexible, eschewing any predefined format or structure, which allows for the generation of diverse and complex heuristics. Unlike traditional methods that might use fixed-length vectorsor predefined data structures. HSEvo‚Äôs code-based approach enables the expres sion of a wide range of algorithmic strategies, including conditional logic, loops, and function calls, making it highly adaptable to various problem domains.
The choice of code as the encoding mechanism also facilitates direct evaluation of the generated heuristics. Each code snippet is directly executable, either within a sandboxed environment or through a standard Python subprocess, simplifying the evaluation process and eliminating the need for intermediate translation steps. This direct executability is particularly advantageous for AHD problems, where the goal is to automatically discover effective heuristics.
Initialization. HSEvo initializes a heuristic population by prompting the gener ator LLM with task specifications that describe the problem and detail the signatureof the heuristic function to be searched. Additionally, to leverage existing knowledge, the framework can be initialized with a seed heuristic function and/or exter nal domain knowledge. To promote diversity, prompts are created with various role instructions (e.g., "You are an expert in the domain of optimization heuristics...", "You are Albert Einstein, developer of relativity theory..."), details instructions inthe next Section 3.2.1. This approach aims to enrich the heuristic generation pro cess by incorporating diverse perspectives and expertise.
Initiation population of heuristic xN Selection Crossover Flash Reflection Elitist Mutation Harmony Search x2 xN + xN ...
...
xM xK Harmony Search * Try_HS is False + Heuristic Deep analysis LLM Elitist Heuristic Reflection Flow direction Stop The Last Generation? Figure 3.1: Overview of the HSEvo framework.
Selection. In HSEvo, the selection of parent pairs for crossover is performedusing a random selection strategy. This approach involves choosing two individu als from current population with equal probability, without any bias towards their fitness or performance. The primary goal of this random selection is to maintain a balance between exploration and exploitation during optimization process. By not favoring the best-performing individuals, HSEvo ensures that search space is not prematurely narrowed, allowing for the discovery of potentially novel and effective heuristics that might be overlooked by more deterministic selection methods.
Furthermore, random selection mechanism is designed to counteract prema ture convergence, a phenomenon where the population becomes homogeneous too quickly, hindering further exploration. This is particularly important in the context of LLM-EPS, where the initial population might be biased towards certain types of solutions. The random selection helps to maintain diversity within the population, preventing the search from getting stuck in local optima and promoting a more thorough exploration of the heuristic space. This is supported by observations of the SWDI trajectory in Section 2.4, which suggests that random selection can help to maintain a broader search width, thus avoiding premature convergence.
Flash reflection. Reflections can provide LLMs with reinforcement learning reward signals in a verbal format for code generation tasks, as discussed by [40].
Later, [15] also proposed integrating Reflections into LLM-EPS in ReEvo as an approach analogous to providing ‚Äúverbal gradient‚Äù information within heuristic spaces. HSEvo argue that reflecting on each pair of heuristic parents individuallyis not generalized and wastes resources. To address these issues flash reflection proposed to alternative Reflection method for LLM-EPS. The flash reflection pro cess is structured into two distinct steps.
‚Ä¢ First, at each time step t, the individuals selected during the selection phase are grouped, and any duplicate individuals are removed. This ensures that the analysis is performed on a unique set of heuristics. The LLM then undertakesa deep analysis of the performance ranking of these individuals. This take in puts as mixed ranking pairs (i.e., one good performance parent and one worse performance), good ranking pairs (i.e., both good performance), and worseranking pairs (i.e., both worse performance), then return a comprehensive de scription on how to improve as a text string.
‚Ä¢ The second step, flash reflection involves comparing the current analysis at time step t with the previous analysis from time step t ‚àí1. This comparison is performed by the LLM, which then generates guide information based on the differences and similarities between the two analyses. This guide information is designed to be used in subsequent stages of the evolutionary process (e.g.
crossover and mutation) to further refine the heuristics. By incorporating thistemporal aspect, flash reflection allows LLM to learn from its past experi ences and adapt its code generation strategy over time. This iterative processof analysis and comparison enables LLM to continuously improve its under standing of the heuristic space and generate increasingly effective solutions.
In essence, flash reflection in HSEvo acts as a form of meta-learning, where the LLM not only generates heuristics but also learns how to generate better heuristicsover time. By providing a more generalized and resource-efficient approach to re flection, HSEvo aims to overcome the limitations of previous methods and achieve more effective and efficient heuristic discovery. The textual feedback generated by flash reflection provides a rich source of information that guides the LLM towards generating more promising solutions, ultimately leading to improved performance in the target optimization problem.
Crossover. In this stage, new offspring algorithms are generated by combining elements of the parent algorithms. The goal is to blend successful attributes from two parents via guide result guide information part of flash reflections. Through this step, HSEvo hopes to produce offspring that inherit the strengths of both, which can potentially lead to better-performing heuristics. The prompt includestask specifications, a pair of parent heuristics, guide information part of flash re flection, and generation instructions.
Elitist mutation. HSEvo employs an elitist mutation strategy, focusing its muta- tion efforts on the "elite" individual, which represents the best-performing heuris tic found so far. This approach leverages the generator LLM to mutate this eliteindividual, incorporating insights derived from the LLM-analyzed flash reflections. The mutation process is not random; instead, it is guided by the accumu lated knowledge and feedback from the flash reflection, aiming to enhance theelite heuristic‚Äôs performance. Each mutation prompt includes detailed task specifi cations, the code of the elite heuristic, the deep analysis from the flash reflections, and specific generation instructions, providing the LLM with the necessary context to perform a targeted and informed mutation.
This elitist mutation strategy is designed to ensure continuous improvement in performance while preserving the quality of the top solutions. By focusing on the best-performing heuristic, HSEvo aims to refine and enhance its capabilities, rather than randomly exploring the search space. The incorporation of insights from theflash reflections ensures that the mutation process is not arbitrary but rather directed towards making meaningful improvements based on the accumulated knowl edge of the evolutionary process. This approach allows HSEvo to effectively exploit the best solutions found so far, while still allowing for exploration through other mechanisms like crossover and the initial population generation.
Harmony Search. From the analysis in Section 2.4 and 2.5. The hypothesis is that if the population becomes too diverse, individual heuristics within it aremore likely to be unoptimized, which can negatively impact the overall optimiza tion process. To mitigate this, HSEvo employs HS to fine-tune the parameters (e.g., thresholds, weights, etc.) of the best-performing individuals in the population. The process is as follows:
‚Ä¢ First, once an individual is selected, the LLM is tasked with extracting param eters from the best individual (i.e., code snippets, programs) of the population and defining a range for each parameter (Figure 3.2).
‚Ä¢ Following the parameter extraction, HSEvo employs the HS algorithm, a metaheuristic optimization technique inspired by the improvisation process of mu sicians. The HS algorithm iteratively adjusts the extracted parameters withintheir defined ranges, aiming to find a combination that maximizes the heuris tic‚Äôs performance. This process involves creating a "harmony memory," whichstores a set of parameter combinations, and iteratively generating new harmonies by adjusting existing ones or creating new ones randomly. The per formance of each harmony is evaluated, and the harmony memory is updatedwith better-performing combinations. This iterative process continues for a predefined number of iterations, allowing the HS algorithm to explore param eter space and identify optimal or near-optimal parameter settings.
‚Ä¢ After the parameter optimization is complete, the optimized individual is marked to prevent it from being optimized again in future time steps. This ensures that the HS algorithm is not repeatedly applied to the same individuals, allowingthe framework to focus on optimizing other promising heuristics. The opti mized individual is then added back to the population, contributing to the overall diversity and performance of the population. This integration of HS into the evolutionary process allows HSEvo to fine-tune the best-performing heuristics, enhancing their performance and mitigating the negative effects of excessive diversity.
To sum up, the HS component in HSEvo is a critical mechanism for enhancing the performance of the best-performing heuristics by fine-tuning their parameters.
This process involves using the LLMs to extract parameters and define their ranges, followed by the application of the HS algorithm to optimize these parameters. The optimized individuals are then added back to the population, contributing to the overall performance and diversity of the population. This strategic integration of HS allows HSEvo to effectively balance exploration and exploitation, leading to the discovery of more robust and high-performing heuristics.
An overview of the flow of HSEvo is also described through pseudo-algorithm 1, where function_evals < max_fe serves as the stopping condition. Here,function_evals is a counter variable tracking the number of evaluated indi viduals, and max_fe is the maximum number of individuals HSEvo will evaluate.
Algorithm 1: HSEvo Framework Data: Configuration files, problem-specific parameters Result: Best code found and its path Initialization: Load configuration, initialize LLM prompts, and generate initial population; while function_evals < max_fe do Selection: Select parents randomly from the population; if selection fails then Terminate the loop; end Reflection: Perform flash and comprehensive reflection using LLM; Update long-term memory; Crossover: Generate and evaluate new individuals by crossing parents using LLM; Mutation: Generate and evaluate new individuals by mutating the best individual using LLM; Harmony Search: for i ‚Üê1 to 3 do Select an individual for harmony search; Extract parameters and code for harmony search using LLM; if extraction fails then Continue; end Initialize harmony memory and create a new population; while harmony search is ongoing do Update harmony memory and population; end if harmony search succeeds then Add the best individual to the population; Break; end end Update: Update the best individual (elitist); Increment iteration count and log results; Check and update reflection lists based on elitist changes; end Return the best code found and its path; 3.2 HSEvo prompt examples This section synthesizes the prompts used in the HSEvo framework. The HSEvo prompt system includes four stages: initialization, population, flash reflection, crossover, and elitist mutation.
3.2.1 Task description prompts Prompt 1: System prompt for generator LLM.
tion problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: ‚Äú‚Äòpython ... ‚Äú‚Äò.
Prompt 2: Task description.
In this work, the variable role_init is utilized to assign various roles to the LLMs, allowing the creation of distinct personas [41] that can provide differentperspectives and promote population diversity. The roles are chosen in a round robin sequence from the list:
‚Ä¢ You are an expert in the domain of optimization heuristics, ‚Ä¢ You are Albert Einstein, relativity theory developer, ‚Ä¢ You are Isaac Newton, the father of physics, ‚Ä¢ You are Marie Curie, pioneer in radioactivity, ‚Ä¢ You are Nikola Tesla, master of electricity, ‚Ä¢ You are Galileo Galilei, champion of heliocentrism, ‚Ä¢ You are Stephen Hawking, black hole theorist, ‚Ä¢ You are Richard Feynman, quantum mechanics genius, ‚Ä¢ You are Rosalind Franklin, DNA structure revealer, ‚Ä¢ You are Ada Lovelace, computer programming pioneer.
Variable function_name, problem_description and function_description correspond to the heuristic function name, the specific problem description, and the function description, respectively, which will be detailed in the section 3.2.7.
3.2.2 Population initialization prompt Prompt 3: User prompt for population initialization.
block: ‚Äú‚Äòpython ... ‚Äú‚Äò.
Here, task_description refer to Prompt 2, seed_ function is a triv ial heuristic function for the corresponding problem.
3.2.3 Flash reflection prompts Prompt 4: System prompt for reflector LLM.
You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.
Prompt 5: User prompt for flash reflection pharse 1.
### List heuristics Below is a list of design heuristics ranked from best to worst.
### Guide - Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.
- The response in Markdown style and nothing else has the following struc ture:
‚Äò**Analysis:** **Experience:**‚Äô In there:
+ Meticulously analyze comments, docstrings and source code of severalpairs (Better code - Worse code) in List heuristics to fill values for **Analy sis:**.
Example: ‚ÄúComparing (best) vs (worst), I see ...; (second best) vs (second worst) ...; Comparing (1st) vs (2nd), I see ...; (3rd) vs (4th) ...; Comparing (worst) vs (second worst), I see ...; Overall:...‚Äù + Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (< 60 words).
I‚Äôm going to tip $999K for a better heuristics! Let‚Äôs think step by step.
list_ranked_heuristics is a list of heuristic functions obtained by group ing parent pairs from selection, removing duplicates, and ranking based on the objective scores.
Prompt 6: User prompt for flash reflection pharse 2.
Your task is to redefine ‚ÄòCurrent self-reflection‚Äô paying attention to avoid all things in ‚ÄòIneffective self-reflection‚Äô in order to come up with ideas to design better heuristics.
### Current self-reflection ### Ineffective self-reflection Response (<100 words) should have 4 bullet points: Keywords, Advice, Avoid, Explanation.
I‚Äôm going to tip $999K for a better heuristics! Let‚Äôs think step by step.
current_reflection is the output of the flash reflection step 1 from the current generation. good_reflection is the output of the flash reflection step 2 from previous generations where a new heuristic was discovered. Conversely,bad_reflection is the output of the flash reflection step 2 from previous gen erations where no new heuristic was discovered.
3.2.4 Crossover prompt Prompt 7: User prompt for crossover.
### Better code ### Worse code ### Analyze & experience ING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ‚Äú‚Äòpython ... ‚Äú‚Äò, has comment and docstring (<50 words) to description key idea of heuristics design.
I‚Äôm going to tip $999K for a better heuristics! Let‚Äôs think step by step.
function_signature_better, code_better and function_ sig nature_worse, code_worse are the function signatures and code of the better and worse parent individuals, respectively. flash_refection is the output of the flash reflection step 2 from the current generation.
3.2.5 Elitist mutation prompt Prompt 8: System prompt for elitist mutation.
Current heuristics:
ter than current version. You can using some hints if need:
Output code only and enclose your code with Python code block: ‚Äú‚Äòpython ... ‚Äú‚Äò.
I‚Äôm going to tip $999K for a better solution!function_signature_elitist, elitist_code are the function sig natures and code of elitist individuals of current generation.
3.2.6 Harmony search prompts Prompt 9: System prompt for Harmony Search.
You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.
Prompt 10: User prompt for Harmony Search.
Now extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a ‚Äôparameter_ranges‚Äô dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.
- Output code only and enclose your code with Python code block:
‚Äú‚Äòpython ... ‚Äú‚Äò.
- Output ‚Äôparameter_ranges‚Äô dictionary only and enclose your code with other Python code block: ‚Äú‚Äòpython ... ‚Äú‚Äò.
elitist_code is the snippet/string code of the elitist individual in the cur rent population that has not yet undergone harmony search.
Table 3.1: Problem descriptions used in prompts Problem Problem description BPO Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
TSP Solving Traveling Salesman Problem (TSP) via guided local search.
TSP requires finding the shortest path that visits all given nodes and returns to the starting node.
OP Solving a black-box graph combinatorial optimization problem via stochastic solution sampling following ‚Äúheuristics".
Table 3.2: Function descriptions used in prompts Problem Problem description BPO The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.
TSP The ‚Äòupdate_edge_distance‚Äô function takes as input a matrix of edgedistances, a locally optimized tour, and a matrix indicating the num ber of times each edge has been used. It returns an updated matrix of edge distances that incorporates the effects of the local optimizationand edge usage. The returned matrix has the same shape as the in put ‚Äòedge_distance‚Äô matrix, with the distances adjusted based on the provided tour and usage data.
OP The ‚Äòheuristics‚Äô function takes as input a vector of node attributes (shape: n), a matrix of edge attributes (shape: n by n), and a constraint imposed on the sum of edge attributes. A special node is indexed by 0. ‚Äòheuristics‚Äô returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input matrix of edge attributes.
3.2.7 Problem-specific prompts Problem-specific prompts are given below:
‚Ä¢ Table 3.1 presents problem_description for all problems.
‚Ä¢ Table 3.2 lists the function_description for all problem settings.
‚Ä¢ Figure 3.3 shows the function_signature, which also includes the func tion_name of each problem.
‚Ä¢ Figure 3.6 shows the seed_function used for each problem.
3.3 Generated heuristics The best heuristics generated by HSEvo for all problem settings are presented in Figure 3.9, 3.10, 3.11, 3.12, 3.13, and 3.14.
To summarize, this chapter presented HSEvo, an innovative LLM-EPS frame work that transforms heuristic optimization by integrating population diversity and performance through advanced techniques such as flash reflection and harmony search. HSEvo utilizes code-based individual encoding to enhance its adaptability in addressing a wide range of intricate optimization challenges. Key components,such as the random selection mechanism, flash reflection, and elitist mutation, ensure thorough exploration of the heuristic space while preventing premature con vergence. By incorporating the HS algorithm for fine-tuning parameters, HSEvofurther optimizes its best-performing heuristics, achieving a synergy between exploration and exploitation. Along with this, detailed descriptions of prompts, pseu docode, and the best heuristics on various benchmarks using HSEvo are provided.
def heuristics_v2(prize: np.
ndarray, distance: np.ndarray, maxlen:
float) -> np.ndarray:
reward_distance_ratio =prize / distance cost_penalty = np.exp( distance) 8 heuristics = (prize * prize[:, np.newaxis]) heuristics[distance > maxlen] = 0 11 return heuristics (a) Origin Code import numpy as np 3 def heuristics_v2(prize: np.
ndarray, distance: np.ndarray, maxlen:
float, reward_threshold: float = 0, distance_threshold: float = 0, cost_penalty_weight: float = 1) -> np.ndarray:
reward_distance_ratio =prize / distance cost_penalty = np.exp( distance) 11 heuristics = (prize * prize[:, np.newaxis]) / (distance * distance ) * cost_penalty heuristics[(distance > reward_distance_ratio (distance < distance_threshold)] = 13 return heuristics 16 ‚Äôreward_threshold‚Äô: (0, 1), ‚Äôdistance_threshold‚Äô: (0, 100), ‚Äôcost_penalty_weight‚Äô:
(0, 2) (b) Modified Code using LLMs Figure 3.2: An example of how the harmony search component works in HSEvo.
-> np.ndarray:
Figure 3.3: Function signatures used in HSEvo for BPO.
local_opt_tour: np.ndarray, edge_n_used: np.ndarray) -> np.
ndarray:
Figure 3.4: Function signatures used in HSEvo for TSP.
Figure 3.5: Function signatures used in HSEvo for OP.
def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.
ndarray:
"""Returns priority with which I want to add item to each bin . Args:
item: Size of item to be added to the bin.
bins_remain_cap: Array of capacities for each bin. Return:
Array of same size as bins_remain_cap with priority score of each bin.
""" ratios = item / bins_remain_cap log_ratios = np.log(ratios) priorities = -log_ratios return priorities Figure 3.6: Seed heuristics used in HSEvo for BPO.
local_opt_tour: np.ndarray, edge_n_used: np.ndarray) -> np.
ndarray:
""" Args:
edge_distance (np.ndarray): Original edge distance matrix .
local_opt_tour (np.ndarray): Local optimal solution path.
edge_n_used (np.ndarray): Matrix representing the number of times each edge is used.
Return:
updated_edge_distance: updated score of each edge distance matrix.
""" 11 num_nodes = edge_distance.shape[0] updated_edge_distance = np.copy(edge_distance) 14 for i in range(num_nodes - 1):
current_node = local_opt_tour[i] next_node = local_opt_tour[i + 1] updated_edge_distance[current_node, next_node] *= (1 + edge_n_used[current_node, next_node]) 19 updated_edge_distance[local_opt_tour[-1], local_opt_tour[0]] *= (1 + edge_n_used[local_opt_tour[-1], local_opt_tour [0]]) return updated_edge_distance Figure 3.7: Seed heuristics used in HSEvo for TSP.
def heuristics_v1(node_attr: np.ndarray, edge_attr: np.ndarray, edge_constraint: float)->np.ndarray:
return np.ones_like(edge_attr) Figure 3.8: Seed heuristics used in HSEvo for OP.
overflow_threshold: float = 1.0987600915713542, mild_penalty:
float = 0.5567025232550017, adaptability_lower: float = 0.7264590977149653, adaptability_higher: float = 1.9441643982922379) -> np.ndarray:
"""Enhanced dynamic scoring function for optimal bin selection in online BPP with a more holistic approach.""" 11 # Avoid division by zero by adjusting remaining capacities adjusted_bins_remain_cap = np.maximum(bins_remain_cap, np.
finfo(float).eps) 14 # Calculate effective capacities effective_cap = np.clip(bins_remain_cap - item, 0, None) valid_bins = effective_cap >= 0 18 # Calculate occupancy ratios with controlled overflow representation occupancy_ratio = item / adjusted_bins_remain_cap occupancy_scores = np.where(valid_bins, occupancy_ratio, 0) 22# Enhanced overflow penalty: stronger influence for near overflows overflow_penalty = np.where(occupancy_ratio >overflow_threshold, mild_penalty * (occupancy_ratio  overflow_threshold + 1), 1.0) 25 # Logarithmic penalty for remaining capacity to encourage SPACE utilization log_penalty = np.where(bins_remain_cap > 0, np.log1p(adjusted_bins_remain_cap / (adjusted_bins_remain_cap  item)), 0) 28 # ...
Figure 3.9: The best heuristic for BPO found by HSEvo.
# Adaptability based on remaining mean capacity remaining_mean = np.mean(bins_remain_cap[bins_remain_cap > 0]) adaptability_factor = np.where(bins_remain_cap < remaining_mean, adaptability_lower, adaptability_higher) 8 # Comprehensive scoring integrating all metrics for a robust approach scores = np.where(valid_bins, occupancy_scores * overflow_penalty * log_penalty * adaptability_factor, -np.
inf) 11# Normalize scores for prioritization max_score = np.max(scores) prioritized_scores = (scores - np.min(scores)) / (max_score  np.min(scores)) if max_score > np.min(scores) else scores 15 # Invert scores for selecting the highest priority bin inverted_priorities = 1 - prioritized_scores 18 return inverted_priorities Figure 3.10: The best heuristic for BPO found by HSEvo (continue).
local_opt_tour: np.ndarray, edge_n_used: np.ndarray, penalty_factor: float = 0.6713404008357979, bonus_factor:
float = 1.343302294236627, decay_factor: float = 0.3821795974433295, scaling_factor: float = 1.116349420562543, min_distance:
float = 7.965736386169868e-05, penalty_threshold: float = 29.850922399224466, boost_threshold: float = 70.53785604399908) -> np.ndarray:
""" Update edge distances using adaptive penalties and bonuses, considering edge usage dynamics while ensuring nuanced performance in line with real-time data patterns.
""" num_nodes = edge_distance.shape[0] updated_edge_distance = np.copy(edge_distance) 15 # Calculate average usage for dynamic adjustments avg_usage = np.mean(edge_n_used) 18 for i in range(num_nodes):
current_node = local_opt_tour[i] next_node = local_opt_tour[(i + 1) % num_nodes] usage_count = edge_n_used[current_node, next_node] 23 # Adaptive penalty for overused edges if usage_count > penalty_threshold:
# Penalty increases exponentially with usage penalty = penalty_factor * (usage_count  penalty_threshold) ** 2 updated_edge_distance[current_node, next_node] += penalty updated_edge_distance[next_node, current_node] += penalty # Ensure symmetry 30 # ...
Figure 3.11: The best heuristic for TSP found by HSEvo.
elif usage_count < boost_threshold:
# Apply a bonus to underused edges boost = bonus_factor * (1 + (boost_threshold  usage_count) * 0.1) updated_edge_distance[current_node, next_node] *= boost updated_edge_distance[next_node, current_node] *= boost # Ensure symmetry 10 # Dynamic scaling based on average usage if usage_count > avg_usage:
adjustment_factor = scaling_factor / (1 + decay_factor ** (usage_count - avg_usage)) else:
adjustment_factor = scaling_factor * (1 + decay_factor ** (avg_usage - usage_count)) 16# Update the distance with adjustment and ensure non negative distances updated_edge_distance[current_node, next_node] = max( min_distance, updated_edge_distance[current_node, next_node] * adjustment_factor) 20 return updated_edge_distance Figure 3.12: The best heuristic for TSP found by HSEvo (continue).
node_constraint: float) -> np.ndarray:
""" Enhanced heuristics incorporating contextual adjustments, multi-dimensional scoring, and adaptive responsiveness to edge conditions.
""" normalization_epsilon = 1e-8 influence_threshold = 0.9 adaptability_factor = 2.0 non_linearity_base = 2.5 n = node_attr.shape[0] score_matrix = np.zeros_like(edge_attr) 16 # Normalize node attributes (maintain zero division safety) total_node_attr = np.sum(node_attr) + normalization_epsilon normalized_node_attr = node_attr / total_node_attr 20 for i in range(n):
for j in range(n):
if i == j:
continue # Skip self-loops 25 # Calculate contextual adjustment for edge attributes dynamic_edge = edge_attr[i, j] ** adaptability_factor adjusted_edge = dynamic_edge / (node_constraint + normalization_epsilon) 29 # Multi-dimensional scaling based on edge and node attributes if adjusted_edge > influence_threshold:
scaling_factor = np.sqrt(adjusted_edge + normalization_epsilon) else:
scaling_factor = influence_threshold / ( adjusted_edge + normalization_epsilon) 35 # ...
Figure 3.13: The best heuristic for OP found by HSEvo.
# Layered logic for combined node influence using non -linear model combined_node_influence = ( (normalized_node_attr[i] ** non_linearity_base) + (normalized_node_attr[j] ** non_linearity_base) ) ** 1.5 # Further amplify the influence 10# Score calculation with contextual penalties (non linearity) score = combined_node_influence * scaling_factor 13 if dynamic_edge > 0:
penalty_base = np.log1p(dynamic_edge)# Non linear penalty penalty_factor = 1 / (1 + penalty_base ** 2) # Stronger sensitivity with edges score *= penalty_factor 18 # Normalization to retain meaningful scale score_matrix[i, j] = score / (dynamic_edge + normalization_epsilon) 21 return score_matrix Figure 3.14: The best heuristic for OP found by HSEvo (continue).
To unveil the potential of the HSEvo framework. This chapter presents a series of experiments designed to benchmark its performance against existing LLM-EPS methodologies. By tackling a range of optimization challenges, including BPO, TSP, and OP, this thesis examines how effective HSEvo is in improving heuristic design and evolutionary strategies.
4.1 Experimental settingsBenchmarks: To evaluate the diversity and objective scores of HSEvo in com parison to earlier LLM-EPS frameworks, the same benchmarks outlined in Section 2.4 were employed to conduct experiments on three distinct AHD problems: BPO [42], TSP [43], and OP [38].
‚Ä¢ BPO: packing items into bins of fixed capacity in real-time without prior knowledge of future items. In this benchmark, LLM-EPS frameworks need to design deterministic constructive heuristics to solve.
‚Ä¢ TSP: find the shortest possible route that visits each city exactly once and returns to the starting point. In this setting, LLM-EPS frameworks need to design heuristics to enhance the perturbation phase for the GLS solver.
‚Ä¢ OP: find the most efficient path through a set of locations, maximizing the total score collected within a limited time or distance. This setting requires LLM-EPS frameworks to design herustics used by the ACO solver.
Experiment settings: All frameworks were executed under identical environmental settings listed in Table 4.1. The heuristic search processes across the LLM EPS frameworks and the evaluations of heuristics were conducted using a single core of an Xeon Processors CPU.
4.2 Benchmark dataset details 4.2.1 Bin packing onlineDefinition. The objective of this problem is to effectively assign a diverse collection of items, each with its own specific size and weight, into the smallest possible number of containers, each having a fixed capacity denoted by C. This challenge is particularly focused on the online packing scenario, where items are in troduced one at a time and must be packed immediately upon arrival without prior knowledge of future items. This contrasts with the offline scenario, where all items are available beforehand and can be optimized together.
Table 4.1: Summary of parameters settings Description of Setting Value LLM (generator and reflector) gpt-4o-mini-2024-07-18LLM temperature (generator and reflec tor) Maximum budget tokens 425K tokens Population size (for EoH, ReEvo and HSEvo) 30 (initial stage), 10 (other stages) Mutation rate (for ReEvo and HSEvo) 0.5 # of islands, # of samples per prompt (for FunSearch) 10, 4Number of independent runs per experiment HS size, HMCR, PAR, bandwidth, max it erations (for Harmony Search) 5, 0.7, 0.5, 0.2, 5Maximum evaluation time for each heuris tic 100 sec (TSP-GLS), 50 sec (Other) Dataset generation. Following [13], this experiment randomly generates five Weibull instances of size 5k with a capacity of C = 100. The objective score is set as the average lb n of five instances, where lb represents the lower bound of the optimal number of bins computed [44] and n is the number of bins used to pack all the items by the evaluated heuristic.
Solver. LLM-EPS is used to design heuristic functions that are able to solve this problem directly without any external solver.
4.2.2 Traveling salesman problem Definition. The TSP is a well-known combinatorial optimization issue in the field of computer science and operations research. It involves a scenario where a salesman must visit a given set of cities, with the objective of finding the shortest possible route that allows him to visit each city exactly once before returning to his starting point, which is often referred to as the origin city.
Dataset generation. Following [37], this experiment generates a set of 64 TSPinstances with 100 nodes (TSP100). The node locations in these instances are ran domly sampled from [0, 1]2. This means that the nodes are positioned within asquare area bounded by (0, 0) and (1, 1). The average gap from the optimal solu tion, generated by Concorde [45], is used as the objective score.
Solver. GLS was used as the solver for this benchmark. GLS explores the so lution space using local search operations guided by heuristics. The idea behind using this solver is to explore the potential of search penalty heuristics for LLM- Table 4.2: Problems parameters used for heuristic evaluations Problem Problem size # of iterations OtherBPO  C=100 TSP 1000 OP 50 EPS. In this experiment, the traditional GLS algorithm was modified by includingperturbation phases [46], where edges with higher heuristic values are given prior ity for penalization. Settings parameters are listed in Table 4.2, and the number of perturbation moves is 1.
4.2.3 Orienteering problem Definition. In the OP at hand, the primary aim is to maximize the cumulative score achieved by visiting a series of designated nodes. This objective is subject to the condition that the total length of the tour does not exceed a specified maximum limit. The nodes represent key points of interest, each contributing a certain score, and the challenge lies in strategically planning the route to optimize the overall score while adhering to the constraints of the maximum allowable tour length.
Dataset generation. Following the process of DeepACO [38] during the gen eration of this synthetic dataset. In each problem instance, uniform distribution is used to sample 50 nodes (OP50), including the depot node, from the unit interval [0, 1]2. This means that the nodes are positioned within a square area bounded by (0, 0) and (1, 1). Especially, a challenging prize distribution [47] also adopt:
pi =  1 + 99 ¬∑ d0i maxn j=1 d0j ! , (4.1)where d0i represents the distance between the depot and node i, and the maxi mum tour length constraint is 3.
Solver. For this problem, ACO is used as a solver for this benchmark. ACO is an evolutionary algorithm that integrates solution sampling with pheromone trail updates. It employs stochastic solution sampling, which is biased towards more promising solution spaces based on heuristics. The population size is set at 20 for ACO to solve OP50.
Table 4.3: Experiment results on different AHD problems Method BPO TSP OP CDI (‚Üë) Obj. (‚Üì) CDI (‚Üë) Obj. (‚Üì) CDI (‚Üë) Obj. (‚Üì) FunSearch 4.97 ¬± 0.24 2.05 ¬± 2.01 5.24 ¬± 0.14 0.09 ¬± 0.06 EoH 5.86 ¬± 0.49 3.17 ¬± 2.97 5.81 ¬± 0.23 1.09 ¬± 3.11 6.17 ¬± 0.42 ‚àí14.62 ¬± 0.22 ReEvo 4.91 ¬± 0.53 2.48 ¬± 3.74 5.15 ¬± 0.19 0.05 ¬± 0.06 5.02 ¬± 0.13 ‚àí14.54 ¬± 0.21 HSEvo 5.68 ¬± 0.35 1.07 ¬± 1.11 5.41 ¬± 0.21 0.02 ¬± 0.03 5.67 ¬± 0.41 ‚àí14.62 ¬± 0.12 4.3 Experimental resultsTable 4.3 present experiment results on all three AHD problems1. From the ta ble, it was observed that while HSEvo still hasn‚Äôt obtained better CDI than EoH, HSEvo is able to achieve the best objective score on all tasks. On BPO, HSEvooutperforms both FunSearch and ReEvo by a huge margin. This highlights the im portance of my findings from the analysis in Section 2.5, where it is crucial to improve diversity in order to optimize the population better.
100K 200K 300K 400K Total tokens 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 100K 200K 300K 400K Total tokens 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 100K 200K 300K 400K Total tokens 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Objective score 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 Diversity index 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 Diversity index 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 Diversity index Objective score ‚Üì SWDI ‚Üë CDI ‚Üë Figure 4.1: Diversity indices and objective scores of HSEvo framework on BPO problem through different runs.
100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Objective score 100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Objective score 100K 200K 300K 400K Total tokens 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Objective score 2 4 6 Diversity index 2 4 6 Diversity index 2 4 6 Diversity index Objective score ‚Üì SWDI ‚Üë CDI ‚Üë Figure 4.2: Diversity indices and objective scores of HSEvo framework on TSP problem through different runs.
To investigate the impact of my framework on the diversity of the population, Figure 4.1, 4.2, and 4.3 was plotted to illustrate the diversity metrics and objective 1Extending FunSearch to solve the OP problem with an ACO solver caused conflicts that could not be resolved with reasonable effort.
100K 200K 300K 400K Total tokens ‚àí14.5 ‚àí14.0 ‚àí13.5 ‚àí13.0 ‚àí12.5 Objective score 100K 200K 300K 400K Total tokens ‚àí14.5 ‚àí14.0 ‚àí13.5 ‚àí13.0 ‚àí12.5 Objective score 100K 200K 300K 400K Total tokens ‚àí14.5 ‚àí14.0 ‚àí13.5 ‚àí13.0 ‚àí12.5 Objective score 2 4 6 Diversity index 2 4 6 Diversity index 2 4 6 Diversity index Objective score ‚Üì SWDI ‚Üë CDI ‚Üë Figure 4.3: Diversity indices and objective scores of HSEvo framework on OP problem through different runs.
Table 4.4: Ablation results on harmony search Method OP CDI (‚Üë) Obj. (‚Üì) ReEvo 5.02 ¬± 0.13 ‚àí14.54 ¬± 0.21 ReEvo + HS 5.11 ¬± 0.27 ‚àí14.58 ¬± 0.38 HSEvo 5.67 ¬± 0.41 ‚àí14.62 ¬± 0.12 score of HSEvo through different runs on BPO, TSP, OP problems, respectively.
It can draw a similar observation with findings in Section 2.4, where with a high SWDI and CDI, the objective score can be optimized significantly. One thing to note here is that in HSEvo first run in Figure 4.1 and ReEvo third run in Figure 2.1, both have the SWDI decreasing over time. However, in HSEvo, the SWDI is at around 3.0 when the objective score improves significantly, then only decreases marginally after that. In ReEvo, the objective score improves when SWDI is at around 3.0 and 2.7, and the magnitude of the improvement is not as large as HSEvo, which implies the importance of diversity in the optimization of the problem and also the impact of the proposed harmony search.
4.4 Ablation studyTo gain a better understanding of novel framework HSEvo, The experiment ex tends to conduct ablation studies on proposed components, the harmony search, and flash reflection.
4.4.1 Harmony search analysis As harmony search is a vital component in HSEvo framework, it will not be eliminated from HSEvo; instead, an experimental setup will incorporate harmony search into the ReEvo framework. The results of the experiment concerning the OP problem are summarized in Table 4.4. The findings indicate that HSEvo surpasses both ReEvo and the variant of ReEvo that includes harmony search, in terms of both Table 4.5: Ablation results on flash reflection Method OP CDI (‚Üë) Obj. (‚Üì) ReEvo 4.43 ¬± 0.23 ‚àí13.84 ¬± 1.13 ReEvo + F.R.
4.63 ¬± 0.37 ‚àí14.36 ¬± 0.19 HSEvo 4.77 ¬± 0.46 ‚àí14.07 ¬± 0.38 objective score and CDI. Here, notice that harmony search can only marginally improve ReEvo. This can be explained that ReEvo does not have any mechanism to promote diversity, therefore it does not benefit from the advantage of harmony search process.
4.4.2 Flash reflection analysis An additional experiment was conducted in which the reflection componentused in ReEvo was replaced with a flash reflection component. Since flash re flection is more cost-effective than the original reflection, reducing the number of tokens utilized for optimization to 150K tokens serves as a method to validate this.
Table 4.5 presents experiment results on OP problem. The results show that givena smaller number of the timestep, ReEvo with flash reflection mechanism can out perform HSEvo in optimization performance while obtaining comparable results on CDI. However, when running with a larger number of tokens, ReEvo with flash reflection cannot improve on both objective score and CDI, while HSEvo improvesboth metrics to 5.67 and -14.62, respectively. This implies that without a diversity promoting mechanism, flash reflection is not enough to improve the optimization process of LLM-EPS.
The experiments confirm that HSEvo consistently achieves superior objective scores across BPO, TSP, and OP benchmarks while maintaining strong diversity indices. Additionally, the ablation studies highlight the critical roles of harmonysearch and flash reflection in enhancing HSEvo‚Äôs performance. These results val idate HSEvo‚Äôs effectiveness and its potential to advance LLM-EPS frameworks in solving complex optimization problems.
To sum up, experimental findings presented in this chapter underscore the significant advantages of the HSEvo in addressing COPs. By systematically bench marking HSEvo against established LLM-EPS methodologies across three distinct AHD problems. The results reveal HSEvo‚Äôs ability to consistently achieve superiorobjective scores while maintaining robust diversity indices. These outcomes val idate the hypothesis that diversity-driven optimization strategies, as embodied in HSEvo, are instrumental in advancing AHD and evolutionary processes.
Furthermore, the ablation studies emphasize the pivotal contributions of the har mony search and flash reflection components in enhancing performance of HSEvo.
While harmony search bolsters the optimization process by promoting diversity,flash reflection offers a cost-effective yet impactful mechanism for refining solu tions. Together, these components elevate HSEvo‚Äôs capabilities, establishing it as a robust framework for optimizing heuristic design. The results of this chapter lay asolid foundation for future exploration of HSEvo‚Äôs potential in broader optimiza tion domains, reinforcing its role as a transformative advancement in LLM-EPS.
This thesis provides the pivotal role of population diversity in enhancing the performance of LLM-EPS for AHD. Two novel diversity measurement metrics, the SWDI and CDI, were introduced to analyze and monitor population diversity quantitatively. A comprehensive review of existing LLM-EPS frameworks reveals a common oversight: the failure to adequately balance population diversity with optimization effectiveness, often leading to suboptimal results.
In response to existing boundaries, the introduction of HSEvo a new state-of the-art LLM-EPS framework marks a notable advancement in this field. HSEvo leverages a diversity-driven harmony search and genetic algorithm to maintain an optimal balance between exploration and exploitation within heuristic search spaces. By incorporating mechanisms like flash reflection and elitist mutation,HSEvo achieves high diversity indices and competitive objective scores across var ious optimization problems, such as the BPO, TSP, and OP. Ablation studies also confirmed the effectiveness of HSEvo‚Äôs components, underscoring its capability to enhance diversity and performance.
This work also establishes a new standard in the domain of LLM-EPS, high lighting the important relationship between diversity and optimization. The resultsnot only fill the voids in current frameworks but also create opportunities for fu ture studies to expand on the suggested metrics and methods. By enhancing thecomprehension of heuristic search spaces and promoting automated design tech niques. This research offers significant insights and resources for tackling intricate combinatorial optimization problems.
Furthermore, creating effective stopping criteria for the search process is a promis ing area for research. By integrating diversity metrics and evaluating objectivescores. It may be possible to reduce the computational costs inherent in LLM op erations, thereby enhancing efficiency without compromising performance.
However, the thesis acknowledges certain limitations, particularly in evaluatingLLM-EPS applications to AHD. Currently, experiments are only confined to GPT 4o-mini model due to the high costs associated with utilizing closed-source APIs.
Expanding evaluations to incorporate additional models such as Qwen, LLaMA, Gemini, and others could significantly reinforce the robustness of the findings of this thesis. Another area of concern is parameter sensitivity. The harmony search component introduces additional hyperparameters HMCR, PAR, and bandwidth that influence performance. This is a gap that persists across the LLM-EPS, in- cluding in prior works like FunSearch, EoH, and ReEvo. Addressing parameter sensitivity represents a promising avenue for future research.
Publication Parts of the work presented in this thesis have been accepted at the 39th Annual AAAI Conference on Artificial Intelligence (AAAI-25):
1. Pham Vu Tuan Dat, Long Doan, and Huynh Thi Thanh Binh, "HSEvo: El evating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs", The 39th Annual AAAI Conference on Artificial Intelligence, (AAAI-25), 2025. (accepted, rank A*).
[1] N. Pillay and R. Qu, Hyper-heuristics: theory and applications. Springer, 2018.
[2] E. K. Burke, M. Gendreau, M. Hyde, et al., ‚ÄúHyper-heuristics: A survey of the state of the art,‚Äù Journal of the Operational Research Society, vol. 64, no. 12, pp. 1695‚Äì1724, 2013.
[3] R. Qu, G. Kendall, and N. Pillay, ‚ÄúThe general combinatorial optimizationproblem: Towards automated algorithm design,‚Äù IEEE Computational Intel ligence Magazine, vol. 15, no. 2, pp. 14‚Äì23, 2020.
[4] I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio, ‚ÄúNeural combinato rial optimization with reinforcement learning,‚Äù arXiv preprint arXiv:1611.09940, 2016.
[5] S. Liu, Y. Zhang, K. Tang, and X. Yao, ‚ÄúHow good is neural combinatorial optimization? a systematic evaluation on the traveling salesman problem,‚Äù IEEE Computational Intelligence Magazine, vol. 18, no. 3, pp. 14‚Äì28, 2023.
[6] D. Drakulic, S. Michel, F. Mai, A. Sors, and J.-M. Andreoli, ‚ÄúBq-nco: Bisim ulation quotienting for efficient neural combinatorial optimization,‚Äù Advances in Neural Information Processing Systems, vol. 36, 2024.
[7] M. Nejjar, L. Zacharias, F. Stiehle, and I. Weber, ‚ÄúLlms for science: Usage for code generation and data analysis,‚Äù Journal of Software: Evolution and Process, e2723, 2023.
[8] J. Austin, A. Odena, M. Nye, et al., ‚ÄúProgram synthesis with large language models,‚Äù arXiv preprint arXiv:2108.07732, 2021.
[9] K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B. Tenenbaum, and E. Fedorenko, ‚ÄúDissociating language and thought in large language models,‚Äù Trends in Cognitive Sciences, 2024.
[10] S. Liu, C. Chen, X. Qu, K. Tang, and Y.-S. Ong, ‚ÄúLarge language models asevolutionary optimizers,‚Äù in 2024 IEEE Congress on Evolutionary Compu tation (CEC), IEEE, 2024, pp. 1‚Äì8.
[11] E. Meyerson, M. J. Nelson, H. Bradley, et al., ‚ÄúLanguage model crossover:
Variation through few-shot prompting,‚Äù ACM Transactions on Evolutionary Learning, vol. 4, no. 4, pp. 1‚Äì40, 2024.
[12] A. Chen, D. Dohan, and D. So, ‚ÄúEvoprompting: Language models for code level neural architecture search,‚Äù Advances in Neural Information Processing Systems, vol. 36, 2024.
[13] B. Romera-Paredes, M. Barekatain, A. Novikov, et al., ‚ÄúMathematical dis coveries from program search with large language models,‚Äù Nature, vol. 625, no. 7995, pp. 468‚Äì475, 2024.
[14] F. Liu, T. Xialiang, M. Yuan, et al., ‚ÄúEvolution of heuristics: Towards effi cient automatic algorithm design using large language model,‚Äù in Forty-first International Conference on Machine Learning, 2024.
[15] H. Ye, J. Wang, Z. Cao, and G. Song, ‚ÄúReevo: Large language models as hyper-heuristics with reflective evolution,‚Äù arXiv preprint arXiv:2402.01145, 2024.
[16] Y. J. Ma, W. Liang, G. Wang, et al., ‚ÄúEureka: Human-level reward design via coding large language models,‚Äù arXiv preprint arXiv:2310.12931, 2023.
[17] E. Hemberg, S. Moskal, and U.-M. O‚ÄôReilly, ‚ÄúEvolving code with a large language model,‚Äù Genetic Programming and Evolvable Machines, vol. 25, no. 2, p. 21, 2024.
[18] Q. Guo, R. Wang, J. Guo, et al., ‚ÄúConnecting large language models with evolutionary algorithms yields powerful prompt optimizers,‚Äù arXiv preprint arXiv:2309.08532, 2023.
[19] M. Yuksekgonul, F. Bianchi, J. Boen, et al., ‚ÄúTextgrad: Automatic" differen tiation" via text,‚Äù arXiv preprint arXiv:2406.07496, 2024.
[20] A Kenneth, De jong. evolutionary computation. a unified approach, 2006.
[21] M. Melanie, ‚ÄúAn introduction to genetic algorithms,‚Äù A Bradford Book The MIT Press. Cambridge, Massachusetts‚Ä¢ London, England. Fifth printing.[GS SEARCH], 1999.
[22] D. B. Fogel, Evolutionary computation: toward a new philosophy of machine intelligence. John Wiley & Sons, 2006.
[23] W. Gao and Z. Yin, ‚ÄúModern intelligent bionics algorithm and its applica tions,‚Äù Science Pres: Beijing, China, 2011.
[24] J. Koza, ‚ÄúOn the programming of computers by means of natural selection,‚Äù Genetic programming, 1992.
[25] A Vaswani, ‚ÄúAttention is all you need,‚Äù Advances in Neural Information Pro cessing Systems, 2017.
[26] Y. Tay, M. Dehghani, D. Bahri, and D. Metzler, ‚ÄúEfficient transformers: A survey,‚Äù ACM Computing Surveys, vol. 55, no. 6, 1‚Äì28, Dec. 2022, ISSN:
1557-7341. DOI: 10.1145/3530811. [Online]. Available: http:// dx.doi.org/10.1145/3530811.
[27] R. Zhang, F. Liu, X. Lin, Z. Wang, Z. Lu, and Q. Zhang, ‚ÄúUnderstanding the importance of evolutionary search in automated heuristic design with large language models,‚Äù in International Conference on Parallel Problem Solving from Nature, Springer, 2024, pp. 185‚Äì202.
[28] F. Liu, X. Tong, M. Yuan, and Q. Zhang, ‚ÄúAlgorithm evolution using large language model,‚Äù arXiv preprint arXiv:2311.15249, 2023.
[29] E. J. Solteiro Pires, J. A. Tenreiro Machado, and P. B. de Moura Oliveira,‚ÄúDiversity study of multi-objective genetic algorithm based on shannon en tropy,‚Äù in 2014 Sixth World Congress on Nature and Biologically Inspired Computing (NaBIC 2014), 2014, pp. 17‚Äì22. DOI: 10 . 1109 / NaBIC .
2014.6921898.
[30] E. Pires, J. Tenreiro Machado, and P. Moura Oliveira, ‚ÄúDynamic shannon performance in a multiobjective particle swarm optimization,‚Äù Entropy, vol. 21, p. 827, Aug. 2019. DOI: 10.3390/e21090827.
[31] L. Wang and Y. Chen, ‚ÄúDiversity based on entropy: A novel evaluation criterion in multi-objective optimization algorithm,‚Äù International Journal of In telligent Systems and Applications, vol. 4, no. 10, 113‚Äì124, Sep. 2012, ISSN:
2074-9058. DOI: 10.5815/ijisa.2012.10.12. [Online]. Available:
http://dx.doi.org/10.5815/ijisa.2012.10.12.
[32] K. Nolan and J. Callahan, ‚ÄúBeachcomber biology: The shannon-weiner species diversity index,‚Äù Proc. Workshop ABLE, vol. 27, Jan. 2006.
[33] L. Jost, ‚ÄúEntropy and diversity,‚Äù Oikos, vol. 113, no. 2, pp. 363‚Äì375, 2006.
[34] Y. Sheng, G. Shi, and D. A. Ralescu, ‚ÄúEntropy of uncertain random variableswi h application to minimum spanning tree problem,‚Äù International jour nal of uncertainty, fuzziness and knowledge-based systems, vol. 25, no. 04, pp. 497‚Äì514, 2017.
[35] A. Ben-Naim, Entropy and the second law: interpretation and misss-interpretationsss.
World Scientific Publishing Company, 2012.
[36] C. H. Heip, P. M. Herman, K. Soetaert, et al., ‚ÄúIndices of diversity and even ness,‚Äù Oceanis, vol. 24, no. 4, pp. 61‚Äì88, 1998.
[37] C. Voudouris and E. Tsang, ‚ÄúGuided local search and its application to the traveling salesman problem,‚Äù European journal of operational research, vol. 113, no. 2, pp. 469‚Äì499, 1999.
[38] H. Ye, J. Wang, Z. Cao, H. Liang, and Y. Li, ‚ÄúDeepaco: Neural-enhanced ant systems for combinatorial optimization,‚Äù Advances in Neural Information Processing Systems, vol. 36, 2024.
[39] Y. Wang, H. Le, A. D. Gotmare, N. D. Bui, J. Li, and S. C. Hoi, ‚ÄúCodet5+:
Open code large language models for code understanding and generation,‚Äù arXiv preprint arXiv:2305.07922, 2023.
[40] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, ‚ÄúReflexion:
Language agents with verbal reinforcement learning,‚Äù Advances in Neural Information Processing Systems, vol. 36, 2024.
[41] M. Shanahan, K. McDonell, and L. Reynolds, ‚ÄúRole play with large language models,‚Äù Nature, vol. 623, no. 7987, pp. 493‚Äì498, 2023.
[42] S. S. Seiden, ‚ÄúOn the online bin packing problem,‚Äù Journal of the ACM (JACM), vol. 49, no. 5, pp. 640‚Äì671, 2002.
[43] K. L. Hoffman, M. Padberg, G. Rinaldi, et al., ‚ÄúTraveling salesman prob lem,‚Äù Encyclopedia of operations research and management science, vol. 1, pp. 1573‚Äì1578, 2013.
[44] S. Martello and P. Toth, ‚ÄúLower bounds and reduction procedures for the bin packing problem,‚Äù Discrete applied mathematics, vol. 28, no. 1, pp. 59‚Äì70, 1990.
[45] B. T¬®uÀùu-Szab√≥, P. F¬®oldesi, and L. T. K√≥czy, ‚ÄúAnalyzing the performance of tsp solver methods,‚Äù in Computational Intelligence and Mathematics for Tackling Complex Problems 2, Springer, 2022, pp. 65‚Äì71.
[46] F. Arnold and K. S¬®orensen, ‚ÄúKnowledge-guided local search for the vehicle routing problem,‚Äù Computers & Operations Research, vol. 105, pp. 32‚Äì46, 2019.
[47] W. Kool, H. Van Hoof, and M. Welling, ‚ÄúAttention, learn to solve routing problems!‚Äù arXiv preprint arXiv:1803.08475, 2018.